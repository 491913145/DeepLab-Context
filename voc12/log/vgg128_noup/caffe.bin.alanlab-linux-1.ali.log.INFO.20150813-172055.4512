Log file created at: 2015/08/13 17:20:55
Running on machine: alanlab-linux-1
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I0813 17:20:55.620896  4512 caffe.cpp:102] Use GPU with device ID 0
I0813 17:20:55.947362  4512 caffe.cpp:110] Starting Optimization
I0813 17:20:55.947480  4512 solver.cpp:32] Initializing solver from parameters: 
train_net: "voc12/config/vgg128_noup/train_train_aug.prototxt"
base_lr: 0.001
display: 10
max_iter: 6000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 2000
snapshot: 2000
snapshot_prefix: "voc12/model/vgg128_noup/train"
solver_mode: GPU
I0813 17:20:55.947617  4512 solver.cpp:58] Creating training net from train_net file: voc12/config/vgg128_noup/train_train_aug.prototxt
I0813 17:20:55.948375  4512 net.cpp:275] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0813 17:20:55.948427  4512 net.cpp:275] The NetState phase (0) differed from the phase (1) specified by a rule in layer fc8_mat
I0813 17:20:55.948655  4512 net.cpp:39] Initializing net from parameters: 
name: "vgg128_noup"
layers {
  top: "data"
  top: "label"
  name: "data"
  type: IMAGE_SEG_DATA
  image_data_param {
    source: "voc12/list/train_aug.txt"
    batch_size: 20
    shuffle: true
    root_folder: "/media/Work_SSD/ali/VOCdevkit/VOC2012"
    label_type: PIXEL
  }
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 306
    mean_value: 104.008
    mean_value: 116.669
    mean_value: 122.675
  }
}
layers {
  bottom: "data"
  top: "conv1_1"
  name: "conv1_1"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layers {
  bottom: "conv1_1"
  top: "conv1_1"
  name: "relu1_1"
  type: RELU
}
layers {
  bottom: "conv1_1"
  top: "conv1_2"
  name: "conv1_2"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layers {
  bottom: "conv1_2"
  top: "conv1_2"
  name: "relu1_2"
  type: RELU
}
layers {
  bottom: "conv1_2"
  top: "pool1"
  name: "pool1"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 1
  }
}
layers {
  bottom: "pool1"
  top: "conv2_1"
  name: "conv2_1"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layers {
  bottom: "conv2_1"
  top: "conv2_1"
  name: "relu2_1"
  type: RELU
}
layers {
  bottom: "conv2_1"
  top: "conv2_2"
  name: "conv2_2"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layers {
  bottom: "conv2_2"
  top: "conv2_2"
  name: "relu2_2"
  type: RELU
}
layers {
  bottom: "conv2_2"
  top: "pool2"
  name: "pool2"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 1
  }
}
layers {
  bottom: "pool2"
  top: "conv3_1"
  name: "conv3_1"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layers {
  bottom: "conv3_1"
  top: "conv3_1"
  name: "relu3_1"
  type: RELU
}
layers {
  bottom: "conv3_1"
  top: "conv3_2"
  name: "conv3_2"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layers {
  bottom: "conv3_2"
  top: "conv3_2"
  name: "relu3_2"
  type: RELU
}
layers {
  bottom: "conv3_2"
  top: "conv3_3"
  name: "conv3_3"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layers {
  bottom: "conv3_3"
  top: "conv3_3"
  name: "relu3_3"
  type: RELU
}
layers {
  bottom: "conv3_3"
  top: "pool3"
  name: "pool3"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 1
  }
}
layers {
  bottom: "pool3"
  top: "conv4_1"
  name: "conv4_1"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layers {
  bottom: "conv4_1"
  top: "conv4_1"
  name: "relu4_1"
  type: RELU
}
layers {
  bottom: "conv4_1"
  top: "conv4_2"
  name: "conv4_2"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layers {
  bottom: "conv4_2"
  top: "conv4_2"
  name: "relu4_2"
  type: RELU
}
layers {
  bottom: "conv4_2"
  top: "conv4_3"
  name: "conv4_3"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layers {
  bottom: "conv4_3"
  top: "conv4_3"
  name: "relu4_3"
  type: RELU
}
layers {
  bottom: "conv4_3"
  top: "pool4"
  name: "pool4"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 1
  }
}
layers {
  bottom: "pool4"
  top: "conv5_1"
  name: "conv5_1"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 512
    pad: 2
    kernel_size: 3
    hole: 2
  }
}
layers {
  bottom: "conv5_1"
  top: "conv5_1"
  name: "relu5_1"
  type: RELU
}
layers {
  bottom: "conv5_1"
  top: "conv5_2"
  name: "conv5_2"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 512
    pad: 2
    kernel_size: 3
    hole: 2
  }
}
layers {
  bottom: "conv5_2"
  top: "conv5_2"
  name: "relu5_2"
  type: RELU
}
layers {
  bottom: "conv5_2"
  top: "conv5_3"
  name: "conv5_3"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 512
    pad: 2
    kernel_size: 3
    hole: 2
  }
}
layers {
  bottom: "conv5_3"
  top: "conv5_3"
  name: "relu5_3"
  type: RELU
}
layers {
  bottom: "conv5_3"
  top: "pool5"
  name: "pool5"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layers {
  bottom: "pool5"
  top: "fc6"
  name: "fc6"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 4096
    pad: 6
    kernel_size: 4
    hole: 4
  }
  strict_dim: false
}
layers {
  bottom: "fc6"
  top: "fc6"
  name: "relu6"
  type: RELU
}
layers {
  bottom: "fc6"
  top: "fc6"
  name: "drop6"
  type: DROPOUT
  dropout_param {
    dropout_ratio: 0.5
  }
}
layers {
  bottom: "fc6"
  top: "fc7"
  name: "fc7"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 4096
    kernel_size: 1
  }
  strict_dim: false
}
layers {
  bottom: "fc7"
  top: "fc7"
  name: "relu7"
  type: RELU
}
layers {
  bottom: "fc7"
  top: "fc7"
  name: "drop7"
  type: DROPOUT
  dropout_param {
    dropout_ratio: 0.5
  }
}
layers {
  bottom: "fc7"
  top: "fc8_pascal"
  name: "fc8_pascal"
  type: CONVOLUTION
  blobs_lr: 10
  blobs_lr: 20
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 21
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
  strict_dim: false
}
layers {
  bottom: "label"
  top: "label_shrink"
  name: "label_shrink"
  type: INTERP
  interp_param {
    shrink_factor: 8
    pad_beg: -1
    pad_end: 0
  }
}
layers {
  bottom: "fc8_pascal"
  bottom: "label_shrink"
  name: "loss"
  type: SOFTMAX_LOSS
  include {
    phase: TRAIN
  }
  softmaxloss_param {
    ignore_label: 255
  }
}
layers {
  bottom: "fc8_pascal"
  bottom: "label_shrink"
  top: "accuracy"
  name: "accuracy"
  type: SEG_ACCURACY
  seg_accuracy_param {
    ignore_label: 255
  }
}
state {
  phase: TRAIN
}
I0813 17:20:55.951556  4512 layer_factory.hpp:78] Creating layer data
I0813 17:20:55.951586  4512 net.cpp:67] Creating Layer data
I0813 17:20:55.951601  4512 net.cpp:356] data -> data
I0813 17:20:55.951625  4512 net.cpp:356] data -> label
I0813 17:20:55.951643  4512 net.cpp:356] data -> (automatic)
I0813 17:20:55.951656  4512 net.cpp:96] Setting up data
I0813 17:20:55.951671  4512 image_seg_data_layer.cpp:45] Opening file voc12/list/train_aug.txt
I0813 17:20:55.962785  4512 image_seg_data_layer.cpp:62] Shuffling data
I0813 17:20:55.964813  4512 image_seg_data_layer.cpp:67] A total of 10582 images.
I0813 17:20:55.966970  4512 image_seg_data_layer.cpp:113] output data size: 20,3,306,306
I0813 17:20:55.966986  4512 image_seg_data_layer.cpp:117] output label size: 20,1,306,306
I0813 17:20:55.966995  4512 image_seg_data_layer.cpp:121] output data_dim size: 20,1,1,2
I0813 17:20:55.978724  4512 net.cpp:103] Top shape: 20 3 306 306 (5618160)
I0813 17:20:55.978741  4512 net.cpp:103] Top shape: 20 1 306 306 (1872720)
I0813 17:20:55.978750  4512 net.cpp:103] Top shape: 20 1 1 2 (40)
I0813 17:20:55.978760  4512 layer_factory.hpp:78] Creating layer conv1_1
I0813 17:20:55.978775  4512 net.cpp:67] Creating Layer conv1_1
I0813 17:20:55.978786  4512 net.cpp:394] conv1_1 <- data
I0813 17:20:55.978801  4512 net.cpp:356] conv1_1 -> conv1_1
I0813 17:20:55.978814  4512 net.cpp:96] Setting up conv1_1
I0813 17:20:55.978901  4512 net.cpp:103] Top shape: 20 64 306 306 (119854080)
I0813 17:20:55.978924  4512 layer_factory.hpp:78] Creating layer relu1_1
I0813 17:20:55.978935  4512 net.cpp:67] Creating Layer relu1_1
I0813 17:20:55.978948  4512 net.cpp:394] relu1_1 <- conv1_1
I0813 17:20:55.978979  4512 net.cpp:345] relu1_1 -> conv1_1 (in-place)
I0813 17:20:55.979001  4512 net.cpp:96] Setting up relu1_1
I0813 17:20:55.979014  4512 net.cpp:103] Top shape: 20 64 306 306 (119854080)
I0813 17:20:55.979024  4512 layer_factory.hpp:78] Creating layer conv1_2
I0813 17:20:55.979038  4512 net.cpp:67] Creating Layer conv1_2
I0813 17:20:55.979049  4512 net.cpp:394] conv1_2 <- conv1_1
I0813 17:20:55.979066  4512 net.cpp:356] conv1_2 -> conv1_2
I0813 17:20:55.979084  4512 net.cpp:96] Setting up conv1_2
I0813 17:20:55.979292  4512 net.cpp:103] Top shape: 20 64 306 306 (119854080)
I0813 17:20:55.979316  4512 layer_factory.hpp:78] Creating layer relu1_2
I0813 17:20:55.979329  4512 net.cpp:67] Creating Layer relu1_2
I0813 17:20:55.979341  4512 net.cpp:394] relu1_2 <- conv1_2
I0813 17:20:55.979360  4512 net.cpp:345] relu1_2 -> conv1_2 (in-place)
I0813 17:20:55.979377  4512 net.cpp:96] Setting up relu1_2
I0813 17:20:55.979393  4512 net.cpp:103] Top shape: 20 64 306 306 (119854080)
I0813 17:20:55.979405  4512 layer_factory.hpp:78] Creating layer pool1
I0813 17:20:55.979421  4512 net.cpp:67] Creating Layer pool1
I0813 17:20:55.979436  4512 net.cpp:394] pool1 <- conv1_2
I0813 17:20:55.979451  4512 net.cpp:356] pool1 -> pool1
I0813 17:20:55.979467  4512 net.cpp:96] Setting up pool1
I0813 17:20:55.979506  4512 net.cpp:103] Top shape: 20 64 154 154 (30356480)
I0813 17:20:55.979521  4512 layer_factory.hpp:78] Creating layer conv2_1
I0813 17:20:55.979537  4512 net.cpp:67] Creating Layer conv2_1
I0813 17:20:55.979552  4512 net.cpp:394] conv2_1 <- pool1
I0813 17:20:55.979578  4512 net.cpp:356] conv2_1 -> conv2_1
I0813 17:20:55.979594  4512 net.cpp:96] Setting up conv2_1
I0813 17:20:55.979835  4512 net.cpp:103] Top shape: 20 128 154 154 (60712960)
I0813 17:20:55.979856  4512 layer_factory.hpp:78] Creating layer relu2_1
I0813 17:20:55.979878  4512 net.cpp:67] Creating Layer relu2_1
I0813 17:20:55.979894  4512 net.cpp:394] relu2_1 <- conv2_1
I0813 17:20:55.979910  4512 net.cpp:345] relu2_1 -> conv2_1 (in-place)
I0813 17:20:55.979925  4512 net.cpp:96] Setting up relu2_1
I0813 17:20:55.979938  4512 net.cpp:103] Top shape: 20 128 154 154 (60712960)
I0813 17:20:55.979948  4512 layer_factory.hpp:78] Creating layer conv2_2
I0813 17:20:55.979964  4512 net.cpp:67] Creating Layer conv2_2
I0813 17:20:55.979976  4512 net.cpp:394] conv2_2 <- conv2_1
I0813 17:20:55.979990  4512 net.cpp:356] conv2_2 -> conv2_2
I0813 17:20:55.980005  4512 net.cpp:96] Setting up conv2_2
I0813 17:20:55.980414  4512 net.cpp:103] Top shape: 20 128 154 154 (60712960)
I0813 17:20:55.980438  4512 layer_factory.hpp:78] Creating layer relu2_2
I0813 17:20:55.980455  4512 net.cpp:67] Creating Layer relu2_2
I0813 17:20:55.980469  4512 net.cpp:394] relu2_2 <- conv2_2
I0813 17:20:55.980484  4512 net.cpp:345] relu2_2 -> conv2_2 (in-place)
I0813 17:20:55.980520  4512 net.cpp:96] Setting up relu2_2
I0813 17:20:55.980532  4512 net.cpp:103] Top shape: 20 128 154 154 (60712960)
I0813 17:20:55.980547  4512 layer_factory.hpp:78] Creating layer pool2
I0813 17:20:55.980563  4512 net.cpp:67] Creating Layer pool2
I0813 17:20:55.980578  4512 net.cpp:394] pool2 <- conv2_2
I0813 17:20:55.980598  4512 net.cpp:356] pool2 -> pool2
I0813 17:20:55.980618  4512 net.cpp:96] Setting up pool2
I0813 17:20:55.980630  4512 net.cpp:103] Top shape: 20 128 78 78 (15575040)
I0813 17:20:55.980643  4512 layer_factory.hpp:78] Creating layer conv3_1
I0813 17:20:55.980654  4512 net.cpp:67] Creating Layer conv3_1
I0813 17:20:55.980667  4512 net.cpp:394] conv3_1 <- pool2
I0813 17:20:55.980680  4512 net.cpp:356] conv3_1 -> conv3_1
I0813 17:20:55.980692  4512 net.cpp:96] Setting up conv3_1
I0813 17:20:55.981493  4512 net.cpp:103] Top shape: 20 256 78 78 (31150080)
I0813 17:20:55.981521  4512 layer_factory.hpp:78] Creating layer relu3_1
I0813 17:20:55.981539  4512 net.cpp:67] Creating Layer relu3_1
I0813 17:20:55.981550  4512 net.cpp:394] relu3_1 <- conv3_1
I0813 17:20:55.981566  4512 net.cpp:345] relu3_1 -> conv3_1 (in-place)
I0813 17:20:55.981582  4512 net.cpp:96] Setting up relu3_1
I0813 17:20:55.981598  4512 net.cpp:103] Top shape: 20 256 78 78 (31150080)
I0813 17:20:55.981613  4512 layer_factory.hpp:78] Creating layer conv3_2
I0813 17:20:55.981629  4512 net.cpp:67] Creating Layer conv3_2
I0813 17:20:55.981643  4512 net.cpp:394] conv3_2 <- conv3_1
I0813 17:20:55.981662  4512 net.cpp:356] conv3_2 -> conv3_2
I0813 17:20:55.981675  4512 net.cpp:96] Setting up conv3_2
I0813 17:20:55.983275  4512 net.cpp:103] Top shape: 20 256 78 78 (31150080)
I0813 17:20:55.983314  4512 layer_factory.hpp:78] Creating layer relu3_2
I0813 17:20:55.983330  4512 net.cpp:67] Creating Layer relu3_2
I0813 17:20:55.983341  4512 net.cpp:394] relu3_2 <- conv3_2
I0813 17:20:55.983355  4512 net.cpp:345] relu3_2 -> conv3_2 (in-place)
I0813 17:20:55.983367  4512 net.cpp:96] Setting up relu3_2
I0813 17:20:55.983378  4512 net.cpp:103] Top shape: 20 256 78 78 (31150080)
I0813 17:20:55.983389  4512 layer_factory.hpp:78] Creating layer conv3_3
I0813 17:20:55.983403  4512 net.cpp:67] Creating Layer conv3_3
I0813 17:20:55.983415  4512 net.cpp:394] conv3_3 <- conv3_2
I0813 17:20:55.983428  4512 net.cpp:356] conv3_3 -> conv3_3
I0813 17:20:55.983440  4512 net.cpp:96] Setting up conv3_3
I0813 17:20:55.984634  4512 net.cpp:103] Top shape: 20 256 78 78 (31150080)
I0813 17:20:55.984657  4512 layer_factory.hpp:78] Creating layer relu3_3
I0813 17:20:55.984673  4512 net.cpp:67] Creating Layer relu3_3
I0813 17:20:55.984685  4512 net.cpp:394] relu3_3 <- conv3_3
I0813 17:20:55.984700  4512 net.cpp:345] relu3_3 -> conv3_3 (in-place)
I0813 17:20:55.984714  4512 net.cpp:96] Setting up relu3_3
I0813 17:20:55.984725  4512 net.cpp:103] Top shape: 20 256 78 78 (31150080)
I0813 17:20:55.984736  4512 layer_factory.hpp:78] Creating layer pool3
I0813 17:20:55.984748  4512 net.cpp:67] Creating Layer pool3
I0813 17:20:55.984760  4512 net.cpp:394] pool3 <- conv3_3
I0813 17:20:55.984772  4512 net.cpp:356] pool3 -> pool3
I0813 17:20:55.984786  4512 net.cpp:96] Setting up pool3
I0813 17:20:55.984798  4512 net.cpp:103] Top shape: 20 256 40 40 (8192000)
I0813 17:20:55.984809  4512 layer_factory.hpp:78] Creating layer conv4_1
I0813 17:20:55.984822  4512 net.cpp:67] Creating Layer conv4_1
I0813 17:20:55.984833  4512 net.cpp:394] conv4_1 <- pool3
I0813 17:20:55.984848  4512 net.cpp:356] conv4_1 -> conv4_1
I0813 17:20:55.984861  4512 net.cpp:96] Setting up conv4_1
I0813 17:20:55.987347  4512 net.cpp:103] Top shape: 20 512 40 40 (16384000)
I0813 17:20:55.987381  4512 layer_factory.hpp:78] Creating layer relu4_1
I0813 17:20:55.987411  4512 net.cpp:67] Creating Layer relu4_1
I0813 17:20:55.987424  4512 net.cpp:394] relu4_1 <- conv4_1
I0813 17:20:55.987440  4512 net.cpp:345] relu4_1 -> conv4_1 (in-place)
I0813 17:20:55.987455  4512 net.cpp:96] Setting up relu4_1
I0813 17:20:55.987468  4512 net.cpp:103] Top shape: 20 512 40 40 (16384000)
I0813 17:20:55.987505  4512 layer_factory.hpp:78] Creating layer conv4_2
I0813 17:20:55.987519  4512 net.cpp:67] Creating Layer conv4_2
I0813 17:20:55.987530  4512 net.cpp:394] conv4_2 <- conv4_1
I0813 17:20:55.987545  4512 net.cpp:356] conv4_2 -> conv4_2
I0813 17:20:55.987560  4512 net.cpp:96] Setting up conv4_2
I0813 17:20:55.992486  4512 net.cpp:103] Top shape: 20 512 40 40 (16384000)
I0813 17:20:55.992529  4512 layer_factory.hpp:78] Creating layer relu4_2
I0813 17:20:55.992576  4512 net.cpp:67] Creating Layer relu4_2
I0813 17:20:55.992597  4512 net.cpp:394] relu4_2 <- conv4_2
I0813 17:20:55.992622  4512 net.cpp:345] relu4_2 -> conv4_2 (in-place)
I0813 17:20:55.992645  4512 net.cpp:96] Setting up relu4_2
I0813 17:20:55.992660  4512 net.cpp:103] Top shape: 20 512 40 40 (16384000)
I0813 17:20:55.992677  4512 layer_factory.hpp:78] Creating layer conv4_3
I0813 17:20:55.992701  4512 net.cpp:67] Creating Layer conv4_3
I0813 17:20:55.992715  4512 net.cpp:394] conv4_3 <- conv4_2
I0813 17:20:55.992736  4512 net.cpp:356] conv4_3 -> conv4_3
I0813 17:20:55.992758  4512 net.cpp:96] Setting up conv4_3
I0813 17:20:55.997473  4512 net.cpp:103] Top shape: 20 512 40 40 (16384000)
I0813 17:20:55.997514  4512 layer_factory.hpp:78] Creating layer relu4_3
I0813 17:20:55.997534  4512 net.cpp:67] Creating Layer relu4_3
I0813 17:20:55.997586  4512 net.cpp:394] relu4_3 <- conv4_3
I0813 17:20:55.997612  4512 net.cpp:345] relu4_3 -> conv4_3 (in-place)
I0813 17:20:55.997637  4512 net.cpp:96] Setting up relu4_3
I0813 17:20:55.997654  4512 net.cpp:103] Top shape: 20 512 40 40 (16384000)
I0813 17:20:55.997673  4512 layer_factory.hpp:78] Creating layer pool4
I0813 17:20:55.997694  4512 net.cpp:67] Creating Layer pool4
I0813 17:20:55.997712  4512 net.cpp:394] pool4 <- conv4_3
I0813 17:20:55.997730  4512 net.cpp:356] pool4 -> pool4
I0813 17:20:55.997755  4512 net.cpp:96] Setting up pool4
I0813 17:20:55.997774  4512 net.cpp:103] Top shape: 20 512 39 39 (15575040)
I0813 17:20:55.997792  4512 layer_factory.hpp:78] Creating layer conv5_1
I0813 17:20:55.997812  4512 net.cpp:67] Creating Layer conv5_1
I0813 17:20:55.997829  4512 net.cpp:394] conv5_1 <- pool4
I0813 17:20:55.997853  4512 net.cpp:356] conv5_1 -> conv5_1
I0813 17:20:55.997874  4512 net.cpp:96] Setting up conv5_1
I0813 17:20:56.002715  4512 net.cpp:103] Top shape: 20 512 39 39 (15575040)
I0813 17:20:56.002769  4512 layer_factory.hpp:78] Creating layer relu5_1
I0813 17:20:56.002787  4512 net.cpp:67] Creating Layer relu5_1
I0813 17:20:56.002835  4512 net.cpp:394] relu5_1 <- conv5_1
I0813 17:20:56.002861  4512 net.cpp:345] relu5_1 -> conv5_1 (in-place)
I0813 17:20:56.002885  4512 net.cpp:96] Setting up relu5_1
I0813 17:20:56.002903  4512 net.cpp:103] Top shape: 20 512 39 39 (15575040)
I0813 17:20:56.002920  4512 layer_factory.hpp:78] Creating layer conv5_2
I0813 17:20:56.002941  4512 net.cpp:67] Creating Layer conv5_2
I0813 17:20:56.002959  4512 net.cpp:394] conv5_2 <- conv5_1
I0813 17:20:56.003001  4512 net.cpp:356] conv5_2 -> conv5_2
I0813 17:20:56.003022  4512 net.cpp:96] Setting up conv5_2
I0813 17:20:56.007896  4512 net.cpp:103] Top shape: 20 512 39 39 (15575040)
I0813 17:20:56.007948  4512 layer_factory.hpp:78] Creating layer relu5_2
I0813 17:20:56.007969  4512 net.cpp:67] Creating Layer relu5_2
I0813 17:20:56.007988  4512 net.cpp:394] relu5_2 <- conv5_2
I0813 17:20:56.008039  4512 net.cpp:345] relu5_2 -> conv5_2 (in-place)
I0813 17:20:56.008065  4512 net.cpp:96] Setting up relu5_2
I0813 17:20:56.008085  4512 net.cpp:103] Top shape: 20 512 39 39 (15575040)
I0813 17:20:56.008102  4512 layer_factory.hpp:78] Creating layer conv5_3
I0813 17:20:56.008122  4512 net.cpp:67] Creating Layer conv5_3
I0813 17:20:56.008143  4512 net.cpp:394] conv5_3 <- conv5_2
I0813 17:20:56.008172  4512 net.cpp:356] conv5_3 -> conv5_3
I0813 17:20:56.008194  4512 net.cpp:96] Setting up conv5_3
I0813 17:20:56.012950  4512 net.cpp:103] Top shape: 20 512 39 39 (15575040)
I0813 17:20:56.012996  4512 layer_factory.hpp:78] Creating layer relu5_3
I0813 17:20:56.013018  4512 net.cpp:67] Creating Layer relu5_3
I0813 17:20:56.013062  4512 net.cpp:394] relu5_3 <- conv5_3
I0813 17:20:56.013113  4512 net.cpp:345] relu5_3 -> conv5_3 (in-place)
I0813 17:20:56.013140  4512 net.cpp:96] Setting up relu5_3
I0813 17:20:56.013159  4512 net.cpp:103] Top shape: 20 512 39 39 (15575040)
I0813 17:20:56.013175  4512 layer_factory.hpp:78] Creating layer pool5
I0813 17:20:56.013196  4512 net.cpp:67] Creating Layer pool5
I0813 17:20:56.013212  4512 net.cpp:394] pool5 <- conv5_3
I0813 17:20:56.013237  4512 net.cpp:356] pool5 -> pool5
I0813 17:20:56.013258  4512 net.cpp:96] Setting up pool5
I0813 17:20:56.013278  4512 net.cpp:103] Top shape: 20 512 39 39 (15575040)
I0813 17:20:56.013295  4512 layer_factory.hpp:78] Creating layer fc6
I0813 17:20:56.013321  4512 net.cpp:67] Creating Layer fc6
I0813 17:20:56.013337  4512 net.cpp:394] fc6 <- pool5
I0813 17:20:56.013356  4512 net.cpp:356] fc6 -> fc6
I0813 17:20:56.013377  4512 net.cpp:96] Setting up fc6
I0813 17:20:56.080225  4512 net.cpp:103] Top shape: 20 4096 39 39 (124600320)
I0813 17:20:56.080286  4512 layer_factory.hpp:78] Creating layer relu6
I0813 17:20:56.080307  4512 net.cpp:67] Creating Layer relu6
I0813 17:20:56.080358  4512 net.cpp:394] relu6 <- fc6
I0813 17:20:56.080379  4512 net.cpp:345] relu6 -> fc6 (in-place)
I0813 17:20:56.080406  4512 net.cpp:96] Setting up relu6
I0813 17:20:56.080426  4512 net.cpp:103] Top shape: 20 4096 39 39 (124600320)
I0813 17:20:56.080447  4512 layer_factory.hpp:78] Creating layer drop6
I0813 17:20:56.080476  4512 net.cpp:67] Creating Layer drop6
I0813 17:20:56.080494  4512 net.cpp:394] drop6 <- fc6
I0813 17:20:56.080517  4512 net.cpp:345] drop6 -> fc6 (in-place)
I0813 17:20:56.080539  4512 net.cpp:96] Setting up drop6
I0813 17:20:56.080561  4512 net.cpp:103] Top shape: 20 4096 39 39 (124600320)
I0813 17:20:56.080581  4512 layer_factory.hpp:78] Creating layer fc7
I0813 17:20:56.080602  4512 net.cpp:67] Creating Layer fc7
I0813 17:20:56.080618  4512 net.cpp:394] fc7 <- fc6
I0813 17:20:56.080638  4512 net.cpp:356] fc7 -> fc7
I0813 17:20:56.080662  4512 net.cpp:96] Setting up fc7
I0813 17:20:56.113730  4512 net.cpp:103] Top shape: 20 4096 39 39 (124600320)
I0813 17:20:56.113785  4512 layer_factory.hpp:78] Creating layer relu7
I0813 17:20:56.113804  4512 net.cpp:67] Creating Layer relu7
I0813 17:20:56.113852  4512 net.cpp:394] relu7 <- fc7
I0813 17:20:56.113872  4512 net.cpp:345] relu7 -> fc7 (in-place)
I0813 17:20:56.113896  4512 net.cpp:96] Setting up relu7
I0813 17:20:56.113919  4512 net.cpp:103] Top shape: 20 4096 39 39 (124600320)
I0813 17:20:56.113942  4512 layer_factory.hpp:78] Creating layer drop7
I0813 17:20:56.113962  4512 net.cpp:67] Creating Layer drop7
I0813 17:20:56.113981  4512 net.cpp:394] drop7 <- fc7
I0813 17:20:56.114003  4512 net.cpp:345] drop7 -> fc7 (in-place)
I0813 17:20:56.114023  4512 net.cpp:96] Setting up drop7
I0813 17:20:56.114043  4512 net.cpp:103] Top shape: 20 4096 39 39 (124600320)
I0813 17:20:56.114063  4512 layer_factory.hpp:78] Creating layer fc8_pascal
I0813 17:20:56.114084  4512 net.cpp:67] Creating Layer fc8_pascal
I0813 17:20:56.114104  4512 net.cpp:394] fc8_pascal <- fc7
I0813 17:20:56.114125  4512 net.cpp:356] fc8_pascal -> fc8_pascal
I0813 17:20:56.114145  4512 net.cpp:96] Setting up fc8_pascal
I0813 17:20:56.117362  4512 net.cpp:103] Top shape: 20 21 39 39 (638820)
I0813 17:20:56.117384  4512 layer_factory.hpp:78] Creating layer fc8_pascal_fc8_pascal_0_split
I0813 17:20:56.117419  4512 net.cpp:67] Creating Layer fc8_pascal_fc8_pascal_0_split
I0813 17:20:56.117442  4512 net.cpp:394] fc8_pascal_fc8_pascal_0_split <- fc8_pascal
I0813 17:20:56.117465  4512 net.cpp:356] fc8_pascal_fc8_pascal_0_split -> fc8_pascal_fc8_pascal_0_split_0
I0813 17:20:56.117493  4512 net.cpp:356] fc8_pascal_fc8_pascal_0_split -> fc8_pascal_fc8_pascal_0_split_1
I0813 17:20:56.117517  4512 net.cpp:96] Setting up fc8_pascal_fc8_pascal_0_split
I0813 17:20:56.117540  4512 net.cpp:103] Top shape: 20 21 39 39 (638820)
I0813 17:20:56.117558  4512 net.cpp:103] Top shape: 20 21 39 39 (638820)
I0813 17:20:56.117575  4512 layer_factory.hpp:78] Creating layer label_shrink
I0813 17:20:56.117632  4512 net.cpp:67] Creating Layer label_shrink
I0813 17:20:56.117653  4512 net.cpp:394] label_shrink <- label
I0813 17:20:56.117674  4512 net.cpp:356] label_shrink -> label_shrink
I0813 17:20:56.117696  4512 net.cpp:96] Setting up label_shrink
I0813 17:20:56.117717  4512 net.cpp:103] Top shape: 20 1 39 39 (30420)
I0813 17:20:56.117735  4512 layer_factory.hpp:78] Creating layer label_shrink_label_shrink_0_split
I0813 17:20:56.117754  4512 net.cpp:67] Creating Layer label_shrink_label_shrink_0_split
I0813 17:20:56.117775  4512 net.cpp:394] label_shrink_label_shrink_0_split <- label_shrink
I0813 17:20:56.117797  4512 net.cpp:356] label_shrink_label_shrink_0_split -> label_shrink_label_shrink_0_split_0
I0813 17:20:56.117818  4512 net.cpp:356] label_shrink_label_shrink_0_split -> label_shrink_label_shrink_0_split_1
I0813 17:20:56.117840  4512 net.cpp:96] Setting up label_shrink_label_shrink_0_split
I0813 17:20:56.117858  4512 net.cpp:103] Top shape: 20 1 39 39 (30420)
I0813 17:20:56.117877  4512 net.cpp:103] Top shape: 20 1 39 39 (30420)
I0813 17:20:56.117893  4512 layer_factory.hpp:78] Creating layer loss
I0813 17:20:56.117919  4512 net.cpp:67] Creating Layer loss
I0813 17:20:56.117936  4512 net.cpp:394] loss <- fc8_pascal_fc8_pascal_0_split_0
I0813 17:20:56.117956  4512 net.cpp:394] loss <- label_shrink_label_shrink_0_split_0
I0813 17:20:56.117981  4512 net.cpp:356] loss -> (automatic)
I0813 17:20:56.118001  4512 net.cpp:96] Setting up loss
I0813 17:20:56.118026  4512 softmax_loss_layer.cpp:40] Weight_Loss file is not provided. Assign all one to it.
I0813 17:20:56.118049  4512 net.cpp:103] Top shape: 1 1 1 1 (1)
I0813 17:20:56.118065  4512 net.cpp:109]     with loss weight 1
I0813 17:20:56.118105  4512 layer_factory.hpp:78] Creating layer accuracy
I0813 17:20:56.118129  4512 net.cpp:67] Creating Layer accuracy
I0813 17:20:56.118144  4512 net.cpp:394] accuracy <- fc8_pascal_fc8_pascal_0_split_1
I0813 17:20:56.118163  4512 net.cpp:394] accuracy <- label_shrink_label_shrink_0_split_1
I0813 17:20:56.118185  4512 net.cpp:356] accuracy -> accuracy
I0813 17:20:56.118207  4512 net.cpp:96] Setting up accuracy
I0813 17:20:56.118237  4512 net.cpp:103] Top shape: 1 1 1 3 (3)
I0813 17:20:56.118252  4512 net.cpp:172] accuracy does not need backward computation.
I0813 17:20:56.118268  4512 net.cpp:170] loss needs backward computation.
I0813 17:20:56.118284  4512 net.cpp:172] label_shrink_label_shrink_0_split does not need backward computation.
I0813 17:20:56.118301  4512 net.cpp:172] label_shrink does not need backward computation.
I0813 17:20:56.118319  4512 net.cpp:170] fc8_pascal_fc8_pascal_0_split needs backward computation.
I0813 17:20:56.118335  4512 net.cpp:170] fc8_pascal needs backward computation.
I0813 17:20:56.118352  4512 net.cpp:170] drop7 needs backward computation.
I0813 17:20:56.118368  4512 net.cpp:170] relu7 needs backward computation.
I0813 17:20:56.118383  4512 net.cpp:170] fc7 needs backward computation.
I0813 17:20:56.118401  4512 net.cpp:170] drop6 needs backward computation.
I0813 17:20:56.118417  4512 net.cpp:170] relu6 needs backward computation.
I0813 17:20:56.118432  4512 net.cpp:170] fc6 needs backward computation.
I0813 17:20:56.118448  4512 net.cpp:170] pool5 needs backward computation.
I0813 17:20:56.118464  4512 net.cpp:170] relu5_3 needs backward computation.
I0813 17:20:56.118481  4512 net.cpp:170] conv5_3 needs backward computation.
I0813 17:20:56.118497  4512 net.cpp:170] relu5_2 needs backward computation.
I0813 17:20:56.118515  4512 net.cpp:170] conv5_2 needs backward computation.
I0813 17:20:56.118531  4512 net.cpp:170] relu5_1 needs backward computation.
I0813 17:20:56.118547  4512 net.cpp:170] conv5_1 needs backward computation.
I0813 17:20:56.118564  4512 net.cpp:170] pool4 needs backward computation.
I0813 17:20:56.118582  4512 net.cpp:170] relu4_3 needs backward computation.
I0813 17:20:56.118598  4512 net.cpp:170] conv4_3 needs backward computation.
I0813 17:20:56.118615  4512 net.cpp:170] relu4_2 needs backward computation.
I0813 17:20:56.118633  4512 net.cpp:170] conv4_2 needs backward computation.
I0813 17:20:56.118662  4512 net.cpp:170] relu4_1 needs backward computation.
I0813 17:20:56.118680  4512 net.cpp:170] conv4_1 needs backward computation.
I0813 17:20:56.118700  4512 net.cpp:170] pool3 needs backward computation.
I0813 17:20:56.118716  4512 net.cpp:170] relu3_3 needs backward computation.
I0813 17:20:56.118733  4512 net.cpp:170] conv3_3 needs backward computation.
I0813 17:20:56.118751  4512 net.cpp:170] relu3_2 needs backward computation.
I0813 17:20:56.118767  4512 net.cpp:170] conv3_2 needs backward computation.
I0813 17:20:56.118782  4512 net.cpp:170] relu3_1 needs backward computation.
I0813 17:20:56.118799  4512 net.cpp:170] conv3_1 needs backward computation.
I0813 17:20:56.118816  4512 net.cpp:170] pool2 needs backward computation.
I0813 17:20:56.118834  4512 net.cpp:170] relu2_2 needs backward computation.
I0813 17:20:56.118849  4512 net.cpp:170] conv2_2 needs backward computation.
I0813 17:20:56.118866  4512 net.cpp:170] relu2_1 needs backward computation.
I0813 17:20:56.118882  4512 net.cpp:170] conv2_1 needs backward computation.
I0813 17:20:56.118901  4512 net.cpp:170] pool1 needs backward computation.
I0813 17:20:56.118916  4512 net.cpp:170] relu1_2 needs backward computation.
I0813 17:20:56.118932  4512 net.cpp:170] conv1_2 needs backward computation.
I0813 17:20:56.118949  4512 net.cpp:170] relu1_1 needs backward computation.
I0813 17:20:56.118974  4512 net.cpp:170] conv1_1 needs backward computation.
I0813 17:20:56.118993  4512 net.cpp:172] data does not need backward computation.
I0813 17:20:56.119007  4512 net.cpp:208] This network produces output accuracy
I0813 17:20:56.119051  4512 net.cpp:467] Collecting Learning Rate and Weight Decay.
I0813 17:20:56.119074  4512 net.cpp:219] Network initialization done.
I0813 17:20:56.119091  4512 net.cpp:220] Memory required for data: 7773188176
I0813 17:20:56.119189  4512 solver.cpp:41] Solver scaffolding done.
I0813 17:20:56.119207  4512 caffe.cpp:118] Finetuning from voc12/model/vgg128_noup/init.caffemodel
I0813 17:20:56.746176  4512 solver.cpp:160] Solving vgg128_noup
I0813 17:20:56.746213  4512 solver.cpp:161] Learning Rate Policy: step
I0813 17:21:03.527938  4512 solver.cpp:209] Iteration 0, loss = 3.38372
I0813 17:21:03.527978  4512 solver.cpp:224]     Train net output #0: accuracy = 0.0291904
I0813 17:21:03.527995  4512 solver.cpp:224]     Train net output #1: accuracy = 0.0398177
I0813 17:21:03.528026  4512 solver.cpp:224]     Train net output #2: accuracy = 0.00920484
I0813 17:21:03.528064  4512 solver.cpp:447] Iteration 0, lr = 0.001
I0813 17:22:10.653501  4512 solver.cpp:209] Iteration 10, loss = 1.12955
I0813 17:22:10.653589  4512 solver.cpp:224]     Train net output #0: accuracy = 0.739486
I0813 17:22:10.653606  4512 solver.cpp:224]     Train net output #1: accuracy = 0.126264
I0813 17:22:10.653636  4512 solver.cpp:224]     Train net output #2: accuracy = 0.202078
I0813 17:22:10.653655  4512 solver.cpp:447] Iteration 10, lr = 0.001
I0813 17:23:17.999861  4512 solver.cpp:209] Iteration 20, loss = 1.10806
I0813 17:23:18.000068  4512 solver.cpp:224]     Train net output #0: accuracy = 0.70366
I0813 17:23:18.000088  4512 solver.cpp:224]     Train net output #1: accuracy = 0.268022
I0813 17:23:18.000103  4512 solver.cpp:224]     Train net output #2: accuracy = 0.34518
I0813 17:23:18.000128  4512 solver.cpp:447] Iteration 20, lr = 0.001
I0813 17:24:25.364778  4512 solver.cpp:209] Iteration 30, loss = 1.16368
I0813 17:24:25.364975  4512 solver.cpp:224]     Train net output #0: accuracy = 0.640316
I0813 17:24:25.364990  4512 solver.cpp:224]     Train net output #1: accuracy = 0.242414
I0813 17:24:25.365000  4512 solver.cpp:224]     Train net output #2: accuracy = 0.21972
I0813 17:24:25.365022  4512 solver.cpp:447] Iteration 30, lr = 0.001
I0813 17:25:32.748302  4512 solver.cpp:209] Iteration 40, loss = 0.787834
I0813 17:25:32.748436  4512 solver.cpp:224]     Train net output #0: accuracy = 0.733872
I0813 17:25:32.748462  4512 solver.cpp:224]     Train net output #1: accuracy = 0.441182
I0813 17:25:32.748471  4512 solver.cpp:224]     Train net output #2: accuracy = 0.402233
I0813 17:25:32.748482  4512 solver.cpp:447] Iteration 40, lr = 0.001
I0813 17:26:40.117738  4512 solver.cpp:209] Iteration 50, loss = 0.774546
I0813 17:26:40.117851  4512 solver.cpp:224]     Train net output #0: accuracy = 0.771062
I0813 17:26:40.117877  4512 solver.cpp:224]     Train net output #1: accuracy = 0.394551
I0813 17:26:40.117885  4512 solver.cpp:224]     Train net output #2: accuracy = 0.374997
I0813 17:26:40.117897  4512 solver.cpp:447] Iteration 50, lr = 0.001
I0813 17:27:47.503821  4512 solver.cpp:209] Iteration 60, loss = 0.967585
I0813 17:27:47.503927  4512 solver.cpp:224]     Train net output #0: accuracy = 0.703892
I0813 17:27:47.503952  4512 solver.cpp:224]     Train net output #1: accuracy = 0.426763
I0813 17:27:47.503962  4512 solver.cpp:224]     Train net output #2: accuracy = 0.242706
I0813 17:27:47.503973  4512 solver.cpp:447] Iteration 60, lr = 0.001
I0813 17:28:54.895153  4512 solver.cpp:209] Iteration 70, loss = 0.658182
I0813 17:28:54.895259  4512 solver.cpp:224]     Train net output #0: accuracy = 0.782346
I0813 17:28:54.895284  4512 solver.cpp:224]     Train net output #1: accuracy = 0.557071
I0813 17:28:54.895293  4512 solver.cpp:224]     Train net output #2: accuracy = 0.482552
I0813 17:28:54.895303  4512 solver.cpp:447] Iteration 70, lr = 0.001
I0813 17:30:02.342403  4512 solver.cpp:209] Iteration 80, loss = 0.611849
I0813 17:30:02.342571  4512 solver.cpp:224]     Train net output #0: accuracy = 0.817409
I0813 17:30:02.342595  4512 solver.cpp:224]     Train net output #1: accuracy = 0.396917
I0813 17:30:02.342604  4512 solver.cpp:224]     Train net output #2: accuracy = 0.325619
I0813 17:30:02.342630  4512 solver.cpp:447] Iteration 80, lr = 0.001
I0813 17:31:09.783265  4512 solver.cpp:209] Iteration 90, loss = 0.872167
I0813 17:31:09.784590  4512 solver.cpp:224]     Train net output #0: accuracy = 0.750454
I0813 17:31:09.784615  4512 solver.cpp:224]     Train net output #1: accuracy = 0.410562
I0813 17:31:09.784625  4512 solver.cpp:224]     Train net output #2: accuracy = 0.264058
I0813 17:31:09.784636  4512 solver.cpp:447] Iteration 90, lr = 0.001
I0813 17:32:17.228930  4512 solver.cpp:209] Iteration 100, loss = 0.693665
I0813 17:32:17.229037  4512 solver.cpp:224]     Train net output #0: accuracy = 0.778023
I0813 17:32:17.229063  4512 solver.cpp:224]     Train net output #1: accuracy = 0.448261
I0813 17:32:17.229071  4512 solver.cpp:224]     Train net output #2: accuracy = 0.420065
I0813 17:32:17.229082  4512 solver.cpp:447] Iteration 100, lr = 0.001
I0813 17:33:24.669256  4512 solver.cpp:209] Iteration 110, loss = 0.641587
I0813 17:33:24.669365  4512 solver.cpp:224]     Train net output #0: accuracy = 0.803905
I0813 17:33:24.669391  4512 solver.cpp:224]     Train net output #1: accuracy = 0.479671
I0813 17:33:24.669400  4512 solver.cpp:224]     Train net output #2: accuracy = 0.283559
I0813 17:33:24.669428  4512 solver.cpp:447] Iteration 110, lr = 0.001
I0813 17:34:32.082643  4512 solver.cpp:209] Iteration 120, loss = 0.577696
I0813 17:34:32.082813  4512 solver.cpp:224]     Train net output #0: accuracy = 0.803914
I0813 17:34:32.082837  4512 solver.cpp:224]     Train net output #1: accuracy = 0.484428
I0813 17:34:32.082846  4512 solver.cpp:224]     Train net output #2: accuracy = 0.284482
I0813 17:34:32.082857  4512 solver.cpp:447] Iteration 120, lr = 0.001
I0813 17:35:39.511334  4512 solver.cpp:209] Iteration 130, loss = 0.778695
I0813 17:35:39.511500  4512 solver.cpp:224]     Train net output #0: accuracy = 0.766868
I0813 17:35:39.511526  4512 solver.cpp:224]     Train net output #1: accuracy = 0.492628
I0813 17:35:39.511535  4512 solver.cpp:224]     Train net output #2: accuracy = 0.341901
I0813 17:35:39.511546  4512 solver.cpp:447] Iteration 130, lr = 0.001
I0813 17:36:46.951849  4512 solver.cpp:209] Iteration 140, loss = 0.497367
I0813 17:36:46.951990  4512 solver.cpp:224]     Train net output #0: accuracy = 0.842283
I0813 17:36:46.952016  4512 solver.cpp:224]     Train net output #1: accuracy = 0.457897
I0813 17:36:46.952025  4512 solver.cpp:224]     Train net output #2: accuracy = 0.324148
I0813 17:36:46.952036  4512 solver.cpp:447] Iteration 140, lr = 0.001
I0813 17:37:54.410989  4512 solver.cpp:209] Iteration 150, loss = 0.666525
I0813 17:37:54.411161  4512 solver.cpp:224]     Train net output #0: accuracy = 0.78602
I0813 17:37:54.411186  4512 solver.cpp:224]     Train net output #1: accuracy = 0.471738
I0813 17:37:54.411195  4512 solver.cpp:224]     Train net output #2: accuracy = 0.285596
I0813 17:37:54.411206  4512 solver.cpp:447] Iteration 150, lr = 0.001
I0813 17:39:01.829713  4512 solver.cpp:209] Iteration 160, loss = 0.562765
I0813 17:39:01.829872  4512 solver.cpp:224]     Train net output #0: accuracy = 0.81492
I0813 17:39:01.829898  4512 solver.cpp:224]     Train net output #1: accuracy = 0.471312
I0813 17:39:01.829907  4512 solver.cpp:224]     Train net output #2: accuracy = 0.451718
I0813 17:39:01.829918  4512 solver.cpp:447] Iteration 160, lr = 0.001
I0813 17:40:09.235507  4512 solver.cpp:209] Iteration 170, loss = 0.708188
I0813 17:40:09.235646  4512 solver.cpp:224]     Train net output #0: accuracy = 0.802676
I0813 17:40:09.235672  4512 solver.cpp:224]     Train net output #1: accuracy = 0.515389
I0813 17:40:09.235682  4512 solver.cpp:224]     Train net output #2: accuracy = 0.479932
I0813 17:40:09.235692  4512 solver.cpp:447] Iteration 170, lr = 0.001
I0813 17:41:16.658466  4512 solver.cpp:209] Iteration 180, loss = 0.748827
I0813 17:41:16.658578  4512 solver.cpp:224]     Train net output #0: accuracy = 0.753053
I0813 17:41:16.658603  4512 solver.cpp:224]     Train net output #1: accuracy = 0.664681
I0813 17:41:16.658632  4512 solver.cpp:224]     Train net output #2: accuracy = 0.412275
I0813 17:41:16.658643  4512 solver.cpp:447] Iteration 180, lr = 0.001
I0813 17:42:24.073459  4512 solver.cpp:209] Iteration 190, loss = 0.551402
I0813 17:42:24.073571  4512 solver.cpp:224]     Train net output #0: accuracy = 0.830194
I0813 17:42:24.073596  4512 solver.cpp:224]     Train net output #1: accuracy = 0.547941
I0813 17:42:24.073606  4512 solver.cpp:224]     Train net output #2: accuracy = 0.409942
I0813 17:42:24.073616  4512 solver.cpp:447] Iteration 190, lr = 0.001
I0813 17:43:31.486531  4512 solver.cpp:209] Iteration 200, loss = 0.595585
I0813 17:43:31.486699  4512 solver.cpp:224]     Train net output #0: accuracy = 0.821514
I0813 17:43:31.486724  4512 solver.cpp:224]     Train net output #1: accuracy = 0.553751
I0813 17:43:31.486747  4512 solver.cpp:224]     Train net output #2: accuracy = 0.394338
I0813 17:43:31.486758  4512 solver.cpp:447] Iteration 200, lr = 0.001
I0813 17:44:38.910118  4512 solver.cpp:209] Iteration 210, loss = 0.5963
I0813 17:44:38.910286  4512 solver.cpp:224]     Train net output #0: accuracy = 0.811607
I0813 17:44:38.910311  4512 solver.cpp:224]     Train net output #1: accuracy = 0.479415
I0813 17:44:38.910332  4512 solver.cpp:224]     Train net output #2: accuracy = 0.394361
I0813 17:44:38.910343  4512 solver.cpp:447] Iteration 210, lr = 0.001
I0813 17:45:46.307653  4512 solver.cpp:209] Iteration 220, loss = 0.579186
I0813 17:45:46.307816  4512 solver.cpp:224]     Train net output #0: accuracy = 0.812388
I0813 17:45:46.307840  4512 solver.cpp:224]     Train net output #1: accuracy = 0.528544
I0813 17:45:46.307849  4512 solver.cpp:224]     Train net output #2: accuracy = 0.451414
I0813 17:45:46.307862  4512 solver.cpp:447] Iteration 220, lr = 0.001
I0813 17:46:53.680723  4512 solver.cpp:209] Iteration 230, loss = 0.585917
I0813 17:46:53.680835  4512 solver.cpp:224]     Train net output #0: accuracy = 0.80785
I0813 17:46:53.680860  4512 solver.cpp:224]     Train net output #1: accuracy = 0.544197
I0813 17:46:53.680881  4512 solver.cpp:224]     Train net output #2: accuracy = 0.491307
I0813 17:46:53.680891  4512 solver.cpp:447] Iteration 230, lr = 0.001
I0813 17:48:01.081699  4512 solver.cpp:209] Iteration 240, loss = 0.87493
I0813 17:48:01.081889  4512 solver.cpp:224]     Train net output #0: accuracy = 0.726625
I0813 17:48:01.081915  4512 solver.cpp:224]     Train net output #1: accuracy = 0.501919
I0813 17:48:01.081925  4512 solver.cpp:224]     Train net output #2: accuracy = 0.307385
I0813 17:48:01.081936  4512 solver.cpp:447] Iteration 240, lr = 0.001
I0813 17:49:08.508350  4512 solver.cpp:209] Iteration 250, loss = 0.502172
I0813 17:49:08.508461  4512 solver.cpp:224]     Train net output #0: accuracy = 0.812364
I0813 17:49:08.508486  4512 solver.cpp:224]     Train net output #1: accuracy = 0.525647
I0813 17:49:08.508496  4512 solver.cpp:224]     Train net output #2: accuracy = 0.415435
I0813 17:49:08.508507  4512 solver.cpp:447] Iteration 250, lr = 0.001
I0813 17:50:15.923367  4512 solver.cpp:209] Iteration 260, loss = 0.345774
I0813 17:50:15.923470  4512 solver.cpp:224]     Train net output #0: accuracy = 0.885304
I0813 17:50:15.923494  4512 solver.cpp:224]     Train net output #1: accuracy = 0.573051
I0813 17:50:15.923504  4512 solver.cpp:224]     Train net output #2: accuracy = 0.472803
I0813 17:50:15.923532  4512 solver.cpp:447] Iteration 260, lr = 0.001
I0813 17:51:23.365605  4512 solver.cpp:209] Iteration 270, loss = 0.527616
I0813 17:51:23.365710  4512 solver.cpp:224]     Train net output #0: accuracy = 0.803117
I0813 17:51:23.365736  4512 solver.cpp:224]     Train net output #1: accuracy = 0.591281
I0813 17:51:23.365746  4512 solver.cpp:224]     Train net output #2: accuracy = 0.472504
I0813 17:51:23.365756  4512 solver.cpp:447] Iteration 270, lr = 0.001
I0813 17:52:30.745712  4512 solver.cpp:209] Iteration 280, loss = 0.47692
I0813 17:52:30.745808  4512 solver.cpp:224]     Train net output #0: accuracy = 0.844811
I0813 17:52:30.745833  4512 solver.cpp:224]     Train net output #1: accuracy = 0.50104
I0813 17:52:30.745843  4512 solver.cpp:224]     Train net output #2: accuracy = 0.294259
I0813 17:52:30.745854  4512 solver.cpp:447] Iteration 280, lr = 0.001
I0813 17:53:38.163652  4512 solver.cpp:209] Iteration 290, loss = 0.716959
