Log file created at: 2015/08/14 12:29:12
Running on machine: alanlab-linux-1
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I0814 12:29:12.684677 26665 caffe.cpp:102] Use GPU with device ID 0
I0814 12:29:12.994391 26665 caffe.cpp:110] Starting Optimization
I0814 12:29:12.994529 26665 solver.cpp:32] Initializing solver from parameters: 
train_net: "voc12/config/vgg128_noup/train_train_aug.prototxt"
base_lr: 0.001
display: 10
max_iter: 6000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 2000
snapshot: 2000
snapshot_prefix: "voc12/model/vgg128_noup/train"
solver_mode: GPU
I0814 12:29:12.994671 26665 solver.cpp:58] Creating training net from train_net file: voc12/config/vgg128_noup/train_train_aug.prototxt
I0814 12:29:12.995368 26665 net.cpp:275] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0814 12:29:12.995410 26665 net.cpp:275] The NetState phase (0) differed from the phase (1) specified by a rule in layer fc8_mat
I0814 12:29:12.995606 26665 net.cpp:39] Initializing net from parameters: 
name: "vgg128_noup"
layers {
  top: "data"
  top: "label"
  name: "data"
  type: IMAGE_SEG_DATA
  image_data_param {
    source: "voc12/list/train_aug.txt"
    batch_size: 20
    shuffle: true
    root_folder: "/media/Work_SSD/ali/VOCdevkit/VOC2012"
    label_type: PIXEL
  }
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 306
    mean_value: 104.008
    mean_value: 116.669
    mean_value: 122.675
  }
}
layers {
  bottom: "data"
  top: "conv1_1"
  name: "conv1_1"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layers {
  bottom: "conv1_1"
  top: "conv1_1"
  name: "relu1_1"
  type: RELU
}
layers {
  bottom: "conv1_1"
  top: "conv1_2"
  name: "conv1_2"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layers {
  bottom: "conv1_2"
  top: "conv1_2"
  name: "relu1_2"
  type: RELU
}
layers {
  bottom: "conv1_2"
  top: "pool1"
  name: "pool1"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 1
  }
}
layers {
  bottom: "pool1"
  top: "conv2_1"
  name: "conv2_1"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layers {
  bottom: "conv2_1"
  top: "conv2_1"
  name: "relu2_1"
  type: RELU
}
layers {
  bottom: "conv2_1"
  top: "conv2_2"
  name: "conv2_2"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layers {
  bottom: "conv2_2"
  top: "conv2_2"
  name: "relu2_2"
  type: RELU
}
layers {
  bottom: "conv2_2"
  top: "pool2"
  name: "pool2"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 1
  }
}
layers {
  bottom: "pool2"
  top: "conv3_1"
  name: "conv3_1"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layers {
  bottom: "conv3_1"
  top: "conv3_1"
  name: "relu3_1"
  type: RELU
}
layers {
  bottom: "conv3_1"
  top: "conv3_2"
  name: "conv3_2"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layers {
  bottom: "conv3_2"
  top: "conv3_2"
  name: "relu3_2"
  type: RELU
}
layers {
  bottom: "conv3_2"
  top: "conv3_3"
  name: "conv3_3"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layers {
  bottom: "conv3_3"
  top: "conv3_3"
  name: "relu3_3"
  type: RELU
}
layers {
  bottom: "conv3_3"
  top: "pool3"
  name: "pool3"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 1
  }
}
layers {
  bottom: "pool3"
  top: "conv4_1"
  name: "conv4_1"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layers {
  bottom: "conv4_1"
  top: "conv4_1"
  name: "relu4_1"
  type: RELU
}
layers {
  bottom: "conv4_1"
  top: "conv4_2"
  name: "conv4_2"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layers {
  bottom: "conv4_2"
  top: "conv4_2"
  name: "relu4_2"
  type: RELU
}
layers {
  bottom: "conv4_2"
  top: "conv4_3"
  name: "conv4_3"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layers {
  bottom: "conv4_3"
  top: "conv4_3"
  name: "relu4_3"
  type: RELU
}
layers {
  bottom: "conv4_3"
  top: "pool4"
  name: "pool4"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 1
  }
}
layers {
  bottom: "pool4"
  top: "conv5_1"
  name: "conv5_1"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 512
    pad: 2
    kernel_size: 3
    hole: 2
  }
}
layers {
  bottom: "conv5_1"
  top: "conv5_1"
  name: "relu5_1"
  type: RELU
}
layers {
  bottom: "conv5_1"
  top: "conv5_2"
  name: "conv5_2"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 512
    pad: 2
    kernel_size: 3
    hole: 2
  }
}
layers {
  bottom: "conv5_2"
  top: "conv5_2"
  name: "relu5_2"
  type: RELU
}
layers {
  bottom: "conv5_2"
  top: "conv5_3"
  name: "conv5_3"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 512
    pad: 2
    kernel_size: 3
    hole: 2
  }
}
layers {
  bottom: "conv5_3"
  top: "conv5_3"
  name: "relu5_3"
  type: RELU
}
layers {
  bottom: "conv5_3"
  top: "pool5"
  name: "pool5"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layers {
  bottom: "pool5"
  top: "fc6"
  name: "fc6"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 4096
    pad: 6
    kernel_size: 4
    hole: 4
  }
  strict_dim: false
}
layers {
  bottom: "fc6"
  top: "fc6"
  name: "relu6"
  type: RELU
}
layers {
  bottom: "fc6"
  top: "fc6"
  name: "drop6"
  type: DROPOUT
  dropout_param {
    dropout_ratio: 0.5
  }
}
layers {
  bottom: "fc6"
  top: "fc7"
  name: "fc7"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 4096
    kernel_size: 1
  }
  strict_dim: false
}
layers {
  bottom: "fc7"
  top: "fc7"
  name: "relu7"
  type: RELU
}
layers {
  bottom: "fc7"
  top: "fc7"
  name: "drop7"
  type: DROPOUT
  dropout_param {
    dropout_ratio: 0.5
  }
}
layers {
  bottom: "fc7"
  top: "fc8_pascal"
  name: "fc8_pascal"
  type: CONVOLUTION
  blobs_lr: 10
  blobs_lr: 20
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 21
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
  strict_dim: false
}
layers {
  bottom: "label"
  top: "label_shrink"
  name: "label_shrink"
  type: INTERP
  interp_param {
    shrink_factor: 8
    pad_beg: -1
    pad_end: 0
  }
}
layers {
  bottom: "fc8_pascal"
  bottom: "label_shrink"
  name: "loss"
  type: SOFTMAX_LOSS
  include {
    phase: TRAIN
  }
  softmaxloss_param {
    ignore_label: 255
  }
}
layers {
  bottom: "fc8_pascal"
  bottom: "label_shrink"
  top: "accuracy"
  name: "accuracy"
  type: SEG_ACCURACY
  seg_accuracy_param {
    ignore_label: 255
  }
}
state {
  phase: TRAIN
}
I0814 12:29:12.998270 26665 layer_factory.hpp:78] Creating layer data
I0814 12:29:12.998301 26665 net.cpp:67] Creating Layer data
I0814 12:29:12.998319 26665 net.cpp:356] data -> data
I0814 12:29:12.998347 26665 net.cpp:356] data -> label
I0814 12:29:12.998370 26665 net.cpp:356] data -> (automatic)
I0814 12:29:12.998388 26665 net.cpp:96] Setting up data
I0814 12:29:12.998405 26665 image_seg_data_layer.cpp:45] Opening file voc12/list/train_aug.txt
I0814 12:29:13.008227 26665 image_seg_data_layer.cpp:62] Shuffling data
I0814 12:29:13.010035 26665 image_seg_data_layer.cpp:67] A total of 10582 images.
I0814 12:29:13.012795 26665 image_seg_data_layer.cpp:113] output data size: 20,3,306,306
I0814 12:29:13.012814 26665 image_seg_data_layer.cpp:117] output label size: 20,1,306,306
I0814 12:29:13.012838 26665 image_seg_data_layer.cpp:121] output data_dim size: 20,1,1,2
I0814 12:29:13.023351 26665 net.cpp:103] Top shape: 20 3 306 306 (5618160)
I0814 12:29:13.023370 26665 net.cpp:103] Top shape: 20 1 306 306 (1872720)
I0814 12:29:13.023393 26665 net.cpp:103] Top shape: 20 1 1 2 (40)
I0814 12:29:13.023413 26665 layer_factory.hpp:78] Creating layer conv1_1
I0814 12:29:13.023435 26665 net.cpp:67] Creating Layer conv1_1
I0814 12:29:13.023452 26665 net.cpp:394] conv1_1 <- data
I0814 12:29:13.023473 26665 net.cpp:356] conv1_1 -> conv1_1
I0814 12:29:13.023494 26665 net.cpp:96] Setting up conv1_1
I0814 12:29:13.023571 26665 net.cpp:103] Top shape: 20 64 306 306 (119854080)
I0814 12:29:13.023597 26665 layer_factory.hpp:78] Creating layer relu1_1
I0814 12:29:13.023615 26665 net.cpp:67] Creating Layer relu1_1
I0814 12:29:13.023632 26665 net.cpp:394] relu1_1 <- conv1_1
I0814 12:29:13.023649 26665 net.cpp:345] relu1_1 -> conv1_1 (in-place)
I0814 12:29:13.023668 26665 net.cpp:96] Setting up relu1_1
I0814 12:29:13.023685 26665 net.cpp:103] Top shape: 20 64 306 306 (119854080)
I0814 12:29:13.023702 26665 layer_factory.hpp:78] Creating layer conv1_2
I0814 12:29:13.023721 26665 net.cpp:67] Creating Layer conv1_2
I0814 12:29:13.023738 26665 net.cpp:394] conv1_2 <- conv1_1
I0814 12:29:13.023761 26665 net.cpp:356] conv1_2 -> conv1_2
I0814 12:29:13.023784 26665 net.cpp:96] Setting up conv1_2
I0814 12:29:13.024016 26665 net.cpp:103] Top shape: 20 64 306 306 (119854080)
I0814 12:29:13.024045 26665 layer_factory.hpp:78] Creating layer relu1_2
I0814 12:29:13.024067 26665 net.cpp:67] Creating Layer relu1_2
I0814 12:29:13.024082 26665 net.cpp:394] relu1_2 <- conv1_2
I0814 12:29:13.024104 26665 net.cpp:345] relu1_2 -> conv1_2 (in-place)
I0814 12:29:13.024124 26665 net.cpp:96] Setting up relu1_2
I0814 12:29:13.024142 26665 net.cpp:103] Top shape: 20 64 306 306 (119854080)
I0814 12:29:13.024159 26665 layer_factory.hpp:78] Creating layer pool1
I0814 12:29:13.024179 26665 net.cpp:67] Creating Layer pool1
I0814 12:29:13.024197 26665 net.cpp:394] pool1 <- conv1_2
I0814 12:29:13.024224 26665 net.cpp:356] pool1 -> pool1
I0814 12:29:13.024243 26665 net.cpp:96] Setting up pool1
I0814 12:29:13.024267 26665 net.cpp:103] Top shape: 20 64 154 154 (30356480)
I0814 12:29:13.024281 26665 layer_factory.hpp:78] Creating layer conv2_1
I0814 12:29:13.024302 26665 net.cpp:67] Creating Layer conv2_1
I0814 12:29:13.024317 26665 net.cpp:394] conv2_1 <- pool1
I0814 12:29:13.024338 26665 net.cpp:356] conv2_1 -> conv2_1
I0814 12:29:13.024355 26665 net.cpp:96] Setting up conv2_1
I0814 12:29:13.024544 26665 net.cpp:103] Top shape: 20 128 154 154 (60712960)
I0814 12:29:13.024571 26665 layer_factory.hpp:78] Creating layer relu2_1
I0814 12:29:13.024595 26665 net.cpp:67] Creating Layer relu2_1
I0814 12:29:13.024615 26665 net.cpp:394] relu2_1 <- conv2_1
I0814 12:29:13.024643 26665 net.cpp:345] relu2_1 -> conv2_1 (in-place)
I0814 12:29:13.024665 26665 net.cpp:96] Setting up relu2_1
I0814 12:29:13.024694 26665 net.cpp:103] Top shape: 20 128 154 154 (60712960)
I0814 12:29:13.024713 26665 layer_factory.hpp:78] Creating layer conv2_2
I0814 12:29:13.024735 26665 net.cpp:67] Creating Layer conv2_2
I0814 12:29:13.024752 26665 net.cpp:394] conv2_2 <- conv2_1
I0814 12:29:13.024776 26665 net.cpp:356] conv2_2 -> conv2_2
I0814 12:29:13.024797 26665 net.cpp:96] Setting up conv2_2
I0814 12:29:13.025214 26665 net.cpp:103] Top shape: 20 128 154 154 (60712960)
I0814 12:29:13.025239 26665 layer_factory.hpp:78] Creating layer relu2_2
I0814 12:29:13.025259 26665 net.cpp:67] Creating Layer relu2_2
I0814 12:29:13.025279 26665 net.cpp:394] relu2_2 <- conv2_2
I0814 12:29:13.025301 26665 net.cpp:345] relu2_2 -> conv2_2 (in-place)
I0814 12:29:13.025351 26665 net.cpp:96] Setting up relu2_2
I0814 12:29:13.025367 26665 net.cpp:103] Top shape: 20 128 154 154 (60712960)
I0814 12:29:13.025394 26665 layer_factory.hpp:78] Creating layer pool2
I0814 12:29:13.025411 26665 net.cpp:67] Creating Layer pool2
I0814 12:29:13.025427 26665 net.cpp:394] pool2 <- conv2_2
I0814 12:29:13.025447 26665 net.cpp:356] pool2 -> pool2
I0814 12:29:13.025465 26665 net.cpp:96] Setting up pool2
I0814 12:29:13.025483 26665 net.cpp:103] Top shape: 20 128 78 78 (15575040)
I0814 12:29:13.025499 26665 layer_factory.hpp:78] Creating layer conv3_1
I0814 12:29:13.025517 26665 net.cpp:67] Creating Layer conv3_1
I0814 12:29:13.025533 26665 net.cpp:394] conv3_1 <- pool2
I0814 12:29:13.025555 26665 net.cpp:356] conv3_1 -> conv3_1
I0814 12:29:13.025573 26665 net.cpp:96] Setting up conv3_1
I0814 12:29:13.026510 26665 net.cpp:103] Top shape: 20 256 78 78 (31150080)
I0814 12:29:13.026532 26665 layer_factory.hpp:78] Creating layer relu3_1
I0814 12:29:13.026551 26665 net.cpp:67] Creating Layer relu3_1
I0814 12:29:13.026567 26665 net.cpp:394] relu3_1 <- conv3_1
I0814 12:29:13.026589 26665 net.cpp:345] relu3_1 -> conv3_1 (in-place)
I0814 12:29:13.026607 26665 net.cpp:96] Setting up relu3_1
I0814 12:29:13.026625 26665 net.cpp:103] Top shape: 20 256 78 78 (31150080)
I0814 12:29:13.026643 26665 layer_factory.hpp:78] Creating layer conv3_2
I0814 12:29:13.026666 26665 net.cpp:67] Creating Layer conv3_2
I0814 12:29:13.026682 26665 net.cpp:394] conv3_2 <- conv3_1
I0814 12:29:13.026703 26665 net.cpp:356] conv3_2 -> conv3_2
I0814 12:29:13.026723 26665 net.cpp:96] Setting up conv3_2
I0814 12:29:13.028100 26665 net.cpp:103] Top shape: 20 256 78 78 (31150080)
I0814 12:29:13.028123 26665 layer_factory.hpp:78] Creating layer relu3_2
I0814 12:29:13.028141 26665 net.cpp:67] Creating Layer relu3_2
I0814 12:29:13.028156 26665 net.cpp:394] relu3_2 <- conv3_2
I0814 12:29:13.028177 26665 net.cpp:345] relu3_2 -> conv3_2 (in-place)
I0814 12:29:13.028193 26665 net.cpp:96] Setting up relu3_2
I0814 12:29:13.028208 26665 net.cpp:103] Top shape: 20 256 78 78 (31150080)
I0814 12:29:13.028224 26665 layer_factory.hpp:78] Creating layer conv3_3
I0814 12:29:13.028240 26665 net.cpp:67] Creating Layer conv3_3
I0814 12:29:13.028254 26665 net.cpp:394] conv3_3 <- conv3_2
I0814 12:29:13.028272 26665 net.cpp:356] conv3_3 -> conv3_3
I0814 12:29:13.028290 26665 net.cpp:96] Setting up conv3_3
I0814 12:29:13.029367 26665 net.cpp:103] Top shape: 20 256 78 78 (31150080)
I0814 12:29:13.029394 26665 layer_factory.hpp:78] Creating layer relu3_3
I0814 12:29:13.029431 26665 net.cpp:67] Creating Layer relu3_3
I0814 12:29:13.029448 26665 net.cpp:394] relu3_3 <- conv3_3
I0814 12:29:13.029467 26665 net.cpp:345] relu3_3 -> conv3_3 (in-place)
I0814 12:29:13.029486 26665 net.cpp:96] Setting up relu3_3
I0814 12:29:13.029502 26665 net.cpp:103] Top shape: 20 256 78 78 (31150080)
I0814 12:29:13.029517 26665 layer_factory.hpp:78] Creating layer pool3
I0814 12:29:13.029533 26665 net.cpp:67] Creating Layer pool3
I0814 12:29:13.029547 26665 net.cpp:394] pool3 <- conv3_3
I0814 12:29:13.029566 26665 net.cpp:356] pool3 -> pool3
I0814 12:29:13.029583 26665 net.cpp:96] Setting up pool3
I0814 12:29:13.029600 26665 net.cpp:103] Top shape: 20 256 40 40 (8192000)
I0814 12:29:13.029615 26665 layer_factory.hpp:78] Creating layer conv4_1
I0814 12:29:13.029638 26665 net.cpp:67] Creating Layer conv4_1
I0814 12:29:13.029650 26665 net.cpp:394] conv4_1 <- pool3
I0814 12:29:13.029670 26665 net.cpp:356] conv4_1 -> conv4_1
I0814 12:29:13.029687 26665 net.cpp:96] Setting up conv4_1
I0814 12:29:13.031924 26665 net.cpp:103] Top shape: 20 512 40 40 (16384000)
I0814 12:29:13.031960 26665 layer_factory.hpp:78] Creating layer relu4_1
I0814 12:29:13.031975 26665 net.cpp:67] Creating Layer relu4_1
I0814 12:29:13.032008 26665 net.cpp:394] relu4_1 <- conv4_1
I0814 12:29:13.032030 26665 net.cpp:345] relu4_1 -> conv4_1 (in-place)
I0814 12:29:13.032050 26665 net.cpp:96] Setting up relu4_1
I0814 12:29:13.032066 26665 net.cpp:103] Top shape: 20 512 40 40 (16384000)
I0814 12:29:13.032105 26665 layer_factory.hpp:78] Creating layer conv4_2
I0814 12:29:13.032124 26665 net.cpp:67] Creating Layer conv4_2
I0814 12:29:13.032137 26665 net.cpp:394] conv4_2 <- conv4_1
I0814 12:29:13.032169 26665 net.cpp:356] conv4_2 -> conv4_2
I0814 12:29:13.032187 26665 net.cpp:96] Setting up conv4_2
I0814 12:29:13.036753 26665 net.cpp:103] Top shape: 20 512 40 40 (16384000)
I0814 12:29:13.036787 26665 layer_factory.hpp:78] Creating layer relu4_2
I0814 12:29:13.036828 26665 net.cpp:67] Creating Layer relu4_2
I0814 12:29:13.036844 26665 net.cpp:394] relu4_2 <- conv4_2
I0814 12:29:13.036864 26665 net.cpp:345] relu4_2 -> conv4_2 (in-place)
I0814 12:29:13.036883 26665 net.cpp:96] Setting up relu4_2
I0814 12:29:13.036898 26665 net.cpp:103] Top shape: 20 512 40 40 (16384000)
I0814 12:29:13.036916 26665 layer_factory.hpp:78] Creating layer conv4_3
I0814 12:29:13.036932 26665 net.cpp:67] Creating Layer conv4_3
I0814 12:29:13.036947 26665 net.cpp:394] conv4_3 <- conv4_2
I0814 12:29:13.036964 26665 net.cpp:356] conv4_3 -> conv4_3
I0814 12:29:13.036983 26665 net.cpp:96] Setting up conv4_3
I0814 12:29:13.041393 26665 net.cpp:103] Top shape: 20 512 40 40 (16384000)
I0814 12:29:13.041427 26665 layer_factory.hpp:78] Creating layer relu4_3
I0814 12:29:13.041445 26665 net.cpp:67] Creating Layer relu4_3
I0814 12:29:13.041458 26665 net.cpp:394] relu4_3 <- conv4_3
I0814 12:29:13.041501 26665 net.cpp:345] relu4_3 -> conv4_3 (in-place)
I0814 12:29:13.041523 26665 net.cpp:96] Setting up relu4_3
I0814 12:29:13.041540 26665 net.cpp:103] Top shape: 20 512 40 40 (16384000)
I0814 12:29:13.041553 26665 layer_factory.hpp:78] Creating layer pool4
I0814 12:29:13.041571 26665 net.cpp:67] Creating Layer pool4
I0814 12:29:13.041584 26665 net.cpp:394] pool4 <- conv4_3
I0814 12:29:13.041604 26665 net.cpp:356] pool4 -> pool4
I0814 12:29:13.041625 26665 net.cpp:96] Setting up pool4
I0814 12:29:13.041642 26665 net.cpp:103] Top shape: 20 512 39 39 (15575040)
I0814 12:29:13.041657 26665 layer_factory.hpp:78] Creating layer conv5_1
I0814 12:29:13.041678 26665 net.cpp:67] Creating Layer conv5_1
I0814 12:29:13.041692 26665 net.cpp:394] conv5_1 <- pool4
I0814 12:29:13.041710 26665 net.cpp:356] conv5_1 -> conv5_1
I0814 12:29:13.041728 26665 net.cpp:96] Setting up conv5_1
I0814 12:29:13.046072 26665 net.cpp:103] Top shape: 20 512 39 39 (15575040)
I0814 12:29:13.046105 26665 layer_factory.hpp:78] Creating layer relu5_1
I0814 12:29:13.046121 26665 net.cpp:67] Creating Layer relu5_1
I0814 12:29:13.046164 26665 net.cpp:394] relu5_1 <- conv5_1
I0814 12:29:13.046182 26665 net.cpp:345] relu5_1 -> conv5_1 (in-place)
I0814 12:29:13.046205 26665 net.cpp:96] Setting up relu5_1
I0814 12:29:13.046222 26665 net.cpp:103] Top shape: 20 512 39 39 (15575040)
I0814 12:29:13.046238 26665 layer_factory.hpp:78] Creating layer conv5_2
I0814 12:29:13.046259 26665 net.cpp:67] Creating Layer conv5_2
I0814 12:29:13.046272 26665 net.cpp:394] conv5_2 <- conv5_1
I0814 12:29:13.046290 26665 net.cpp:356] conv5_2 -> conv5_2
I0814 12:29:13.046308 26665 net.cpp:96] Setting up conv5_2
I0814 12:29:13.050671 26665 net.cpp:103] Top shape: 20 512 39 39 (15575040)
I0814 12:29:13.050712 26665 layer_factory.hpp:78] Creating layer relu5_2
I0814 12:29:13.050729 26665 net.cpp:67] Creating Layer relu5_2
I0814 12:29:13.050742 26665 net.cpp:394] relu5_2 <- conv5_2
I0814 12:29:13.050761 26665 net.cpp:345] relu5_2 -> conv5_2 (in-place)
I0814 12:29:13.050806 26665 net.cpp:96] Setting up relu5_2
I0814 12:29:13.050825 26665 net.cpp:103] Top shape: 20 512 39 39 (15575040)
I0814 12:29:13.050838 26665 layer_factory.hpp:78] Creating layer conv5_3
I0814 12:29:13.050858 26665 net.cpp:67] Creating Layer conv5_3
I0814 12:29:13.050874 26665 net.cpp:394] conv5_3 <- conv5_2
I0814 12:29:13.050894 26665 net.cpp:356] conv5_3 -> conv5_3
I0814 12:29:13.050915 26665 net.cpp:96] Setting up conv5_3
I0814 12:29:13.055104 26665 net.cpp:103] Top shape: 20 512 39 39 (15575040)
I0814 12:29:13.055135 26665 layer_factory.hpp:78] Creating layer relu5_3
I0814 12:29:13.055152 26665 net.cpp:67] Creating Layer relu5_3
I0814 12:29:13.055166 26665 net.cpp:394] relu5_3 <- conv5_3
I0814 12:29:13.055212 26665 net.cpp:345] relu5_3 -> conv5_3 (in-place)
I0814 12:29:13.055250 26665 net.cpp:96] Setting up relu5_3
I0814 12:29:13.055268 26665 net.cpp:103] Top shape: 20 512 39 39 (15575040)
I0814 12:29:13.055284 26665 layer_factory.hpp:78] Creating layer pool5
I0814 12:29:13.055305 26665 net.cpp:67] Creating Layer pool5
I0814 12:29:13.055318 26665 net.cpp:394] pool5 <- conv5_3
I0814 12:29:13.055336 26665 net.cpp:356] pool5 -> pool5
I0814 12:29:13.055356 26665 net.cpp:96] Setting up pool5
I0814 12:29:13.055374 26665 net.cpp:103] Top shape: 20 512 39 39 (15575040)
I0814 12:29:13.055389 26665 layer_factory.hpp:78] Creating layer fc6
I0814 12:29:13.055414 26665 net.cpp:67] Creating Layer fc6
I0814 12:29:13.055428 26665 net.cpp:394] fc6 <- pool5
I0814 12:29:13.055449 26665 net.cpp:356] fc6 -> fc6
I0814 12:29:13.055465 26665 net.cpp:96] Setting up fc6
I0814 12:29:13.115937 26665 net.cpp:103] Top shape: 20 4096 39 39 (124600320)
I0814 12:29:13.115979 26665 layer_factory.hpp:78] Creating layer relu6
I0814 12:29:13.115998 26665 net.cpp:67] Creating Layer relu6
I0814 12:29:13.116040 26665 net.cpp:394] relu6 <- fc6
I0814 12:29:13.116060 26665 net.cpp:345] relu6 -> fc6 (in-place)
I0814 12:29:13.116080 26665 net.cpp:96] Setting up relu6
I0814 12:29:13.116097 26665 net.cpp:103] Top shape: 20 4096 39 39 (124600320)
I0814 12:29:13.116114 26665 layer_factory.hpp:78] Creating layer drop6
I0814 12:29:13.116139 26665 net.cpp:67] Creating Layer drop6
I0814 12:29:13.116156 26665 net.cpp:394] drop6 <- fc6
I0814 12:29:13.116174 26665 net.cpp:345] drop6 -> fc6 (in-place)
I0814 12:29:13.116194 26665 net.cpp:96] Setting up drop6
I0814 12:29:13.116214 26665 net.cpp:103] Top shape: 20 4096 39 39 (124600320)
I0814 12:29:13.116230 26665 layer_factory.hpp:78] Creating layer fc7
I0814 12:29:13.116247 26665 net.cpp:67] Creating Layer fc7
I0814 12:29:13.116262 26665 net.cpp:394] fc7 <- fc6
I0814 12:29:13.116281 26665 net.cpp:356] fc7 -> fc7
I0814 12:29:13.116302 26665 net.cpp:96] Setting up fc7
I0814 12:29:13.146116 26665 net.cpp:103] Top shape: 20 4096 39 39 (124600320)
I0814 12:29:13.146165 26665 layer_factory.hpp:78] Creating layer relu7
I0814 12:29:13.146183 26665 net.cpp:67] Creating Layer relu7
I0814 12:29:13.146227 26665 net.cpp:394] relu7 <- fc7
I0814 12:29:13.146247 26665 net.cpp:345] relu7 -> fc7 (in-place)
I0814 12:29:13.146270 26665 net.cpp:96] Setting up relu7
I0814 12:29:13.146286 26665 net.cpp:103] Top shape: 20 4096 39 39 (124600320)
I0814 12:29:13.146303 26665 layer_factory.hpp:78] Creating layer drop7
I0814 12:29:13.146322 26665 net.cpp:67] Creating Layer drop7
I0814 12:29:13.146337 26665 net.cpp:394] drop7 <- fc7
I0814 12:29:13.146353 26665 net.cpp:345] drop7 -> fc7 (in-place)
I0814 12:29:13.146370 26665 net.cpp:96] Setting up drop7
I0814 12:29:13.146389 26665 net.cpp:103] Top shape: 20 4096 39 39 (124600320)
I0814 12:29:13.146404 26665 layer_factory.hpp:78] Creating layer fc8_pascal
I0814 12:29:13.146423 26665 net.cpp:67] Creating Layer fc8_pascal
I0814 12:29:13.146436 26665 net.cpp:394] fc8_pascal <- fc7
I0814 12:29:13.146455 26665 net.cpp:356] fc8_pascal -> fc8_pascal
I0814 12:29:13.146474 26665 net.cpp:96] Setting up fc8_pascal
I0814 12:29:13.149338 26665 net.cpp:103] Top shape: 20 21 39 39 (638820)
I0814 12:29:13.149358 26665 layer_factory.hpp:78] Creating layer fc8_pascal_fc8_pascal_0_split
I0814 12:29:13.149387 26665 net.cpp:67] Creating Layer fc8_pascal_fc8_pascal_0_split
I0814 12:29:13.149405 26665 net.cpp:394] fc8_pascal_fc8_pascal_0_split <- fc8_pascal
I0814 12:29:13.149427 26665 net.cpp:356] fc8_pascal_fc8_pascal_0_split -> fc8_pascal_fc8_pascal_0_split_0
I0814 12:29:13.149449 26665 net.cpp:356] fc8_pascal_fc8_pascal_0_split -> fc8_pascal_fc8_pascal_0_split_1
I0814 12:29:13.149471 26665 net.cpp:96] Setting up fc8_pascal_fc8_pascal_0_split
I0814 12:29:13.149490 26665 net.cpp:103] Top shape: 20 21 39 39 (638820)
I0814 12:29:13.149507 26665 net.cpp:103] Top shape: 20 21 39 39 (638820)
I0814 12:29:13.149523 26665 layer_factory.hpp:78] Creating layer label_shrink
I0814 12:29:13.149575 26665 net.cpp:67] Creating Layer label_shrink
I0814 12:29:13.149595 26665 net.cpp:394] label_shrink <- label
I0814 12:29:13.149613 26665 net.cpp:356] label_shrink -> label_shrink
I0814 12:29:13.149633 26665 net.cpp:96] Setting up label_shrink
I0814 12:29:13.149655 26665 net.cpp:103] Top shape: 20 1 39 39 (30420)
I0814 12:29:13.149672 26665 layer_factory.hpp:78] Creating layer label_shrink_label_shrink_0_split
I0814 12:29:13.149688 26665 net.cpp:67] Creating Layer label_shrink_label_shrink_0_split
I0814 12:29:13.149701 26665 net.cpp:394] label_shrink_label_shrink_0_split <- label_shrink
I0814 12:29:13.149719 26665 net.cpp:356] label_shrink_label_shrink_0_split -> label_shrink_label_shrink_0_split_0
I0814 12:29:13.149741 26665 net.cpp:356] label_shrink_label_shrink_0_split -> label_shrink_label_shrink_0_split_1
I0814 12:29:13.149761 26665 net.cpp:96] Setting up label_shrink_label_shrink_0_split
I0814 12:29:13.149778 26665 net.cpp:103] Top shape: 20 1 39 39 (30420)
I0814 12:29:13.149794 26665 net.cpp:103] Top shape: 20 1 39 39 (30420)
I0814 12:29:13.149809 26665 layer_factory.hpp:78] Creating layer loss
I0814 12:29:13.149834 26665 net.cpp:67] Creating Layer loss
I0814 12:29:13.149849 26665 net.cpp:394] loss <- fc8_pascal_fc8_pascal_0_split_0
I0814 12:29:13.149865 26665 net.cpp:394] loss <- label_shrink_label_shrink_0_split_0
I0814 12:29:13.149886 26665 net.cpp:356] loss -> (automatic)
I0814 12:29:13.149905 26665 net.cpp:96] Setting up loss
I0814 12:29:13.149930 26665 softmax_loss_layer.cpp:40] Weight_Loss file is not provided. Assign all one to it.
I0814 12:29:13.149950 26665 net.cpp:103] Top shape: 1 1 1 1 (1)
I0814 12:29:13.149966 26665 net.cpp:109]     with loss weight 1
I0814 12:29:13.150007 26665 layer_factory.hpp:78] Creating layer accuracy
I0814 12:29:13.150033 26665 net.cpp:67] Creating Layer accuracy
I0814 12:29:13.150049 26665 net.cpp:394] accuracy <- fc8_pascal_fc8_pascal_0_split_1
I0814 12:29:13.150068 26665 net.cpp:394] accuracy <- label_shrink_label_shrink_0_split_1
I0814 12:29:13.150087 26665 net.cpp:356] accuracy -> accuracy
I0814 12:29:13.150106 26665 net.cpp:96] Setting up accuracy
I0814 12:29:13.150133 26665 net.cpp:103] Top shape: 1 1 1 3 (3)
I0814 12:29:13.150149 26665 net.cpp:172] accuracy does not need backward computation.
I0814 12:29:13.150163 26665 net.cpp:170] loss needs backward computation.
I0814 12:29:13.150178 26665 net.cpp:172] label_shrink_label_shrink_0_split does not need backward computation.
I0814 12:29:13.150194 26665 net.cpp:172] label_shrink does not need backward computation.
I0814 12:29:13.150208 26665 net.cpp:170] fc8_pascal_fc8_pascal_0_split needs backward computation.
I0814 12:29:13.150223 26665 net.cpp:170] fc8_pascal needs backward computation.
I0814 12:29:13.150238 26665 net.cpp:170] drop7 needs backward computation.
I0814 12:29:13.150252 26665 net.cpp:170] relu7 needs backward computation.
I0814 12:29:13.150267 26665 net.cpp:170] fc7 needs backward computation.
I0814 12:29:13.150282 26665 net.cpp:170] drop6 needs backward computation.
I0814 12:29:13.150297 26665 net.cpp:170] relu6 needs backward computation.
I0814 12:29:13.150311 26665 net.cpp:170] fc6 needs backward computation.
I0814 12:29:13.150326 26665 net.cpp:170] pool5 needs backward computation.
I0814 12:29:13.150342 26665 net.cpp:170] relu5_3 needs backward computation.
I0814 12:29:13.150357 26665 net.cpp:170] conv5_3 needs backward computation.
I0814 12:29:13.150372 26665 net.cpp:170] relu5_2 needs backward computation.
I0814 12:29:13.150387 26665 net.cpp:170] conv5_2 needs backward computation.
I0814 12:29:13.150401 26665 net.cpp:170] relu5_1 needs backward computation.
I0814 12:29:13.150416 26665 net.cpp:170] conv5_1 needs backward computation.
I0814 12:29:13.150431 26665 net.cpp:170] pool4 needs backward computation.
I0814 12:29:13.150446 26665 net.cpp:170] relu4_3 needs backward computation.
I0814 12:29:13.150460 26665 net.cpp:170] conv4_3 needs backward computation.
I0814 12:29:13.150476 26665 net.cpp:170] relu4_2 needs backward computation.
I0814 12:29:13.150491 26665 net.cpp:170] conv4_2 needs backward computation.
I0814 12:29:13.150516 26665 net.cpp:170] relu4_1 needs backward computation.
I0814 12:29:13.150531 26665 net.cpp:170] conv4_1 needs backward computation.
I0814 12:29:13.150547 26665 net.cpp:170] pool3 needs backward computation.
I0814 12:29:13.150562 26665 net.cpp:170] relu3_3 needs backward computation.
I0814 12:29:13.150578 26665 net.cpp:170] conv3_3 needs backward computation.
I0814 12:29:13.150591 26665 net.cpp:170] relu3_2 needs backward computation.
I0814 12:29:13.150606 26665 net.cpp:170] conv3_2 needs backward computation.
I0814 12:29:13.150620 26665 net.cpp:170] relu3_1 needs backward computation.
I0814 12:29:13.150635 26665 net.cpp:170] conv3_1 needs backward computation.
I0814 12:29:13.150651 26665 net.cpp:170] pool2 needs backward computation.
I0814 12:29:13.150666 26665 net.cpp:170] relu2_2 needs backward computation.
I0814 12:29:13.150681 26665 net.cpp:170] conv2_2 needs backward computation.
I0814 12:29:13.150696 26665 net.cpp:170] relu2_1 needs backward computation.
I0814 12:29:13.150712 26665 net.cpp:170] conv2_1 needs backward computation.
I0814 12:29:13.150727 26665 net.cpp:170] pool1 needs backward computation.
I0814 12:29:13.150743 26665 net.cpp:170] relu1_2 needs backward computation.
I0814 12:29:13.150758 26665 net.cpp:170] conv1_2 needs backward computation.
I0814 12:29:13.150773 26665 net.cpp:170] relu1_1 needs backward computation.
I0814 12:29:13.150786 26665 net.cpp:170] conv1_1 needs backward computation.
I0814 12:29:13.150801 26665 net.cpp:172] data does not need backward computation.
I0814 12:29:13.150815 26665 net.cpp:208] This network produces output accuracy
I0814 12:29:13.150854 26665 net.cpp:467] Collecting Learning Rate and Weight Decay.
I0814 12:29:13.150876 26665 net.cpp:219] Network initialization done.
I0814 12:29:13.150889 26665 net.cpp:220] Memory required for data: 7773188176
I0814 12:29:13.151000 26665 solver.cpp:41] Solver scaffolding done.
I0814 12:29:13.151027 26665 caffe.cpp:115] Resuming from voc12/model/vgg128_noup/train_iter_4000.solverstate
I0814 12:29:13.151043 26665 solver.cpp:160] Solving vgg128_noup
I0814 12:29:13.151058 26665 solver.cpp:161] Learning Rate Policy: step
I0814 12:29:13.151103 26665 solver.cpp:167] Restoring previous solver status from voc12/model/vgg128_noup/train_iter_4000.solverstate
I0814 12:29:14.060434 26665 solver.cpp:562] SGDSolver: restoring history
I0814 12:29:20.988340 26665 solver.cpp:209] Iteration 4000, loss = 0.269868
I0814 12:29:20.988381 26665 solver.cpp:224]     Train net output #0: accuracy = 0.906568
I0814 12:29:20.988397 26665 solver.cpp:224]     Train net output #1: accuracy = 0.714969
I0814 12:29:20.988425 26665 solver.cpp:224]     Train net output #2: accuracy = 0.591444
I0814 12:29:20.988471 26665 solver.cpp:447] Iteration 4000, lr = 1e-05
I0814 12:30:28.205132 26665 solver.cpp:209] Iteration 4010, loss = 0.341892
I0814 12:30:28.205215 26665 solver.cpp:224]     Train net output #0: accuracy = 0.880247
I0814 12:30:28.205234 26665 solver.cpp:224]     Train net output #1: accuracy = 0.695151
I0814 12:30:28.205262 26665 solver.cpp:224]     Train net output #2: accuracy = 0.54774
I0814 12:30:28.205281 26665 solver.cpp:447] Iteration 4010, lr = 1e-05
I0814 12:31:35.595717 26665 solver.cpp:209] Iteration 4020, loss = 0.313677
I0814 12:31:35.595844 26665 solver.cpp:224]     Train net output #0: accuracy = 0.889091
I0814 12:31:35.595862 26665 solver.cpp:224]     Train net output #1: accuracy = 0.82125
I0814 12:31:35.595877 26665 solver.cpp:224]     Train net output #2: accuracy = 0.584959
I0814 12:31:35.595895 26665 solver.cpp:447] Iteration 4020, lr = 1e-05
I0814 12:32:42.969219 26665 solver.cpp:209] Iteration 4030, loss = 0.369162
I0814 12:32:42.969331 26665 solver.cpp:224]     Train net output #0: accuracy = 0.888974
I0814 12:32:42.969359 26665 solver.cpp:224]     Train net output #1: accuracy = 0.782017
I0814 12:32:42.969374 26665 solver.cpp:224]     Train net output #2: accuracy = 0.670739
I0814 12:32:42.969391 26665 solver.cpp:447] Iteration 4030, lr = 1e-05
I0814 12:33:50.355237 26665 solver.cpp:209] Iteration 4040, loss = 0.422923
I0814 12:33:50.355376 26665 solver.cpp:224]     Train net output #0: accuracy = 0.85529
I0814 12:33:50.355407 26665 solver.cpp:224]     Train net output #1: accuracy = 0.714081
I0814 12:33:50.355423 26665 solver.cpp:224]     Train net output #2: accuracy = 0.33955
I0814 12:33:50.355456 26665 solver.cpp:447] Iteration 4040, lr = 1e-05
I0814 12:34:57.738437 26665 solver.cpp:209] Iteration 4050, loss = 0.265281
I0814 12:34:57.738643 26665 solver.cpp:224]     Train net output #0: accuracy = 0.906839
I0814 12:34:57.738659 26665 solver.cpp:224]     Train net output #1: accuracy = 0.719095
I0814 12:34:57.738668 26665 solver.cpp:224]     Train net output #2: accuracy = 0.484067
I0814 12:34:57.738692 26665 solver.cpp:447] Iteration 4050, lr = 1e-05
I0814 12:36:05.177165 26665 solver.cpp:209] Iteration 4060, loss = 0.237895
I0814 12:36:05.177280 26665 solver.cpp:224]     Train net output #0: accuracy = 0.913894
I0814 12:36:05.177306 26665 solver.cpp:224]     Train net output #1: accuracy = 0.788844
I0814 12:36:05.177315 26665 solver.cpp:224]     Train net output #2: accuracy = 0.652752
I0814 12:36:05.177327 26665 solver.cpp:447] Iteration 4060, lr = 1e-05
I0814 12:37:12.629557 26665 solver.cpp:209] Iteration 4070, loss = 0.311538
I0814 12:37:12.629674 26665 solver.cpp:224]     Train net output #0: accuracy = 0.889327
I0814 12:37:12.629700 26665 solver.cpp:224]     Train net output #1: accuracy = 0.749567
I0814 12:37:12.629710 26665 solver.cpp:224]     Train net output #2: accuracy = 0.665572
I0814 12:37:12.629721 26665 solver.cpp:447] Iteration 4070, lr = 1e-05
I0814 12:38:20.082101 26665 solver.cpp:209] Iteration 4080, loss = 0.431105
I0814 12:38:20.082209 26665 solver.cpp:224]     Train net output #0: accuracy = 0.860117
I0814 12:38:20.082236 26665 solver.cpp:224]     Train net output #1: accuracy = 0.662537
I0814 12:38:20.082263 26665 solver.cpp:224]     Train net output #2: accuracy = 0.385366
I0814 12:38:20.082275 26665 solver.cpp:447] Iteration 4080, lr = 1e-05
I0814 12:39:27.529608 26665 solver.cpp:209] Iteration 4090, loss = 0.351174
I0814 12:39:27.529716 26665 solver.cpp:224]     Train net output #0: accuracy = 0.882954
I0814 12:39:27.529742 26665 solver.cpp:224]     Train net output #1: accuracy = 0.825481
I0814 12:39:27.529752 26665 solver.cpp:224]     Train net output #2: accuracy = 0.595052
I0814 12:39:27.529763 26665 solver.cpp:447] Iteration 4090, lr = 1e-05
I0814 12:40:35.001713 26665 solver.cpp:209] Iteration 4100, loss = 0.315712
I0814 12:40:35.001816 26665 solver.cpp:224]     Train net output #0: accuracy = 0.890837
I0814 12:40:35.001842 26665 solver.cpp:224]     Train net output #1: accuracy = 0.630894
I0814 12:40:35.001850 26665 solver.cpp:224]     Train net output #2: accuracy = 0.525048
I0814 12:40:35.001862 26665 solver.cpp:447] Iteration 4100, lr = 1e-05
I0814 12:41:42.452074 26665 solver.cpp:209] Iteration 4110, loss = 0.272262
I0814 12:41:42.452180 26665 solver.cpp:224]     Train net output #0: accuracy = 0.895884
I0814 12:41:42.452206 26665 solver.cpp:224]     Train net output #1: accuracy = 0.690658
I0814 12:41:42.452215 26665 solver.cpp:224]     Train net output #2: accuracy = 0.629549
I0814 12:41:42.452226 26665 solver.cpp:447] Iteration 4110, lr = 1e-05
I0814 12:42:49.890434 26665 solver.cpp:209] Iteration 4120, loss = 0.350753
I0814 12:42:49.890597 26665 solver.cpp:224]     Train net output #0: accuracy = 0.868468
I0814 12:42:49.890624 26665 solver.cpp:224]     Train net output #1: accuracy = 0.712247
I0814 12:42:49.890633 26665 solver.cpp:224]     Train net output #2: accuracy = 0.566469
I0814 12:42:49.890645 26665 solver.cpp:447] Iteration 4120, lr = 1e-05
I0814 12:43:57.371170 26665 solver.cpp:209] Iteration 4130, loss = 0.390633
I0814 12:43:57.371330 26665 solver.cpp:224]     Train net output #0: accuracy = 0.867833
I0814 12:43:57.371356 26665 solver.cpp:224]     Train net output #1: accuracy = 0.749584
I0814 12:43:57.371366 26665 solver.cpp:224]     Train net output #2: accuracy = 0.525939
I0814 12:43:57.371394 26665 solver.cpp:447] Iteration 4130, lr = 1e-05
I0814 12:45:04.800812 26665 solver.cpp:209] Iteration 4140, loss = 0.338753
I0814 12:45:04.800943 26665 solver.cpp:224]     Train net output #0: accuracy = 0.896977
I0814 12:45:04.800971 26665 solver.cpp:224]     Train net output #1: accuracy = 0.730572
I0814 12:45:04.800981 26665 solver.cpp:224]     Train net output #2: accuracy = 0.58012
I0814 12:45:04.800992 26665 solver.cpp:447] Iteration 4140, lr = 1e-05
I0814 12:46:12.268600 26665 solver.cpp:209] Iteration 4150, loss = 0.371581
I0814 12:46:12.268712 26665 solver.cpp:224]     Train net output #0: accuracy = 0.867948
I0814 12:46:12.268736 26665 solver.cpp:224]     Train net output #1: accuracy = 0.614564
I0814 12:46:12.268764 26665 solver.cpp:224]     Train net output #2: accuracy = 0.450754
I0814 12:46:12.268779 26665 solver.cpp:447] Iteration 4150, lr = 1e-05
I0814 12:47:19.742893 26665 solver.cpp:209] Iteration 4160, loss = 0.310505
I0814 12:47:19.743000 26665 solver.cpp:224]     Train net output #0: accuracy = 0.890489
I0814 12:47:19.743024 26665 solver.cpp:224]     Train net output #1: accuracy = 0.637488
I0814 12:47:19.743034 26665 solver.cpp:224]     Train net output #2: accuracy = 0.521324
I0814 12:47:19.743046 26665 solver.cpp:447] Iteration 4160, lr = 1e-05
I0814 12:48:27.177546 26665 solver.cpp:209] Iteration 4170, loss = 0.474277
I0814 12:48:27.177649 26665 solver.cpp:224]     Train net output #0: accuracy = 0.828675
I0814 12:48:27.177675 26665 solver.cpp:224]     Train net output #1: accuracy = 0.636453
I0814 12:48:27.177700 26665 solver.cpp:224]     Train net output #2: accuracy = 0.357534
I0814 12:48:27.177711 26665 solver.cpp:447] Iteration 4170, lr = 1e-05
I0814 12:49:34.636515 26665 solver.cpp:209] Iteration 4180, loss = 0.284761
I0814 12:49:34.636679 26665 solver.cpp:224]     Train net output #0: accuracy = 0.893467
I0814 12:49:34.636704 26665 solver.cpp:224]     Train net output #1: accuracy = 0.762481
I0814 12:49:34.636734 26665 solver.cpp:224]     Train net output #2: accuracy = 0.547689
I0814 12:49:34.636745 26665 solver.cpp:447] Iteration 4180, lr = 1e-05
I0814 12:50:42.089114 26665 solver.cpp:209] Iteration 4190, loss = 0.298863
I0814 12:50:42.089273 26665 solver.cpp:224]     Train net output #0: accuracy = 0.898577
I0814 12:50:42.089298 26665 solver.cpp:224]     Train net output #1: accuracy = 0.623841
I0814 12:50:42.089308 26665 solver.cpp:224]     Train net output #2: accuracy = 0.497381
I0814 12:50:42.089340 26665 solver.cpp:447] Iteration 4190, lr = 1e-05
I0814 12:51:49.562361 26665 solver.cpp:209] Iteration 4200, loss = 0.275348
I0814 12:51:49.562521 26665 solver.cpp:224]     Train net output #0: accuracy = 0.910984
I0814 12:51:49.562547 26665 solver.cpp:224]     Train net output #1: accuracy = 0.583414
I0814 12:51:49.562572 26665 solver.cpp:224]     Train net output #2: accuracy = 0.512907
I0814 12:51:49.562583 26665 solver.cpp:447] Iteration 4200, lr = 1e-05
I0814 12:52:57.003984 26665 solver.cpp:209] Iteration 4210, loss = 0.356741
I0814 12:52:57.004083 26665 solver.cpp:224]     Train net output #0: accuracy = 0.892158
I0814 12:52:57.004097 26665 solver.cpp:224]     Train net output #1: accuracy = 0.636414
I0814 12:52:57.004118 26665 solver.cpp:224]     Train net output #2: accuracy = 0.491563
I0814 12:52:57.004149 26665 solver.cpp:447] Iteration 4210, lr = 1e-05
I0814 12:54:04.431457 26665 solver.cpp:209] Iteration 4220, loss = 0.373173
I0814 12:54:04.431565 26665 solver.cpp:224]     Train net output #0: accuracy = 0.875572
I0814 12:54:04.431591 26665 solver.cpp:224]     Train net output #1: accuracy = 0.684664
I0814 12:54:04.431599 26665 solver.cpp:224]     Train net output #2: accuracy = 0.552216
I0814 12:54:04.431612 26665 solver.cpp:447] Iteration 4220, lr = 1e-05
I0814 12:55:11.888108 26665 solver.cpp:209] Iteration 4230, loss = 0.300663
I0814 12:55:11.888207 26665 solver.cpp:224]     Train net output #0: accuracy = 0.90156
I0814 12:55:11.888233 26665 solver.cpp:224]     Train net output #1: accuracy = 0.636426
I0814 12:55:11.888257 26665 solver.cpp:224]     Train net output #2: accuracy = 0.42907
I0814 12:55:11.888268 26665 solver.cpp:447] Iteration 4230, lr = 1e-05
I0814 12:56:19.314002 26665 solver.cpp:209] Iteration 4240, loss = 0.32562
I0814 12:56:19.314185 26665 solver.cpp:224]     Train net output #0: accuracy = 0.889357
I0814 12:56:19.314213 26665 solver.cpp:224]     Train net output #1: accuracy = 0.699249
I0814 12:56:19.314223 26665 solver.cpp:224]     Train net output #2: accuracy = 0.508318
I0814 12:56:19.314250 26665 solver.cpp:447] Iteration 4240, lr = 1e-05
I0814 12:57:26.744174 26665 solver.cpp:209] Iteration 4250, loss = 0.33941
I0814 12:57:26.744284 26665 solver.cpp:224]     Train net output #0: accuracy = 0.8892
I0814 12:57:26.744310 26665 solver.cpp:224]     Train net output #1: accuracy = 0.700468
I0814 12:57:26.744320 26665 solver.cpp:224]     Train net output #2: accuracy = 0.471005
I0814 12:57:26.744333 26665 solver.cpp:447] Iteration 4250, lr = 1e-05
I0814 12:58:34.147861 26665 solver.cpp:209] Iteration 4260, loss = 0.382753
I0814 12:58:34.148016 26665 solver.cpp:224]     Train net output #0: accuracy = 0.870846
I0814 12:58:34.148043 26665 solver.cpp:224]     Train net output #1: accuracy = 0.796265
I0814 12:58:34.148052 26665 solver.cpp:224]     Train net output #2: accuracy = 0.668771
I0814 12:58:34.148064 26665 solver.cpp:447] Iteration 4260, lr = 1e-05
I0814 12:59:41.553735 26665 solver.cpp:209] Iteration 4270, loss = 0.394903
I0814 12:59:41.553901 26665 solver.cpp:224]     Train net output #0: accuracy = 0.868241
I0814 12:59:41.553926 26665 solver.cpp:224]     Train net output #1: accuracy = 0.712915
I0814 12:59:41.553957 26665 solver.cpp:224]     Train net output #2: accuracy = 0.560261
I0814 12:59:41.553972 26665 solver.cpp:447] Iteration 4270, lr = 1e-05
I0814 13:00:48.998891 26665 solver.cpp:209] Iteration 4280, loss = 0.371025
I0814 13:00:48.999002 26665 solver.cpp:224]     Train net output #0: accuracy = 0.882787
I0814 13:00:48.999027 26665 solver.cpp:224]     Train net output #1: accuracy = 0.786272
I0814 13:00:48.999037 26665 solver.cpp:224]     Train net output #2: accuracy = 0.436565
I0814 13:00:48.999048 26665 solver.cpp:447] Iteration 4280, lr = 1e-05
I0814 13:01:56.417191 26665 solver.cpp:209] Iteration 4290, loss = 0.362299
I0814 13:01:56.417302 26665 solver.cpp:224]     Train net output #0: accuracy = 0.875878
I0814 13:01:56.417327 26665 solver.cpp:224]     Train net output #1: accuracy = 0.598128
I0814 13:01:56.417351 26665 solver.cpp:224]     Train net output #2: accuracy = 0.535165
I0814 13:01:56.417362 26665 solver.cpp:447] Iteration 4290, lr = 1e-05
I0814 13:03:03.817803 26665 solver.cpp:209] Iteration 4300, loss = 0.268718
I0814 13:03:03.817906 26665 solver.cpp:224]     Train net output #0: accuracy = 0.899477
I0814 13:03:03.817931 26665 solver.cpp:224]     Train net output #1: accuracy = 0.767105
I0814 13:03:03.817960 26665 solver.cpp:224]     Train net output #2: accuracy = 0.577361
I0814 13:03:03.817973 26665 solver.cpp:447] Iteration 4300, lr = 1e-05
I0814 13:04:11.255450 26665 solver.cpp:209] Iteration 4310, loss = 0.338477
I0814 13:04:11.255558 26665 solver.cpp:224]     Train net output #0: accuracy = 0.887196
I0814 13:04:11.255584 26665 solver.cpp:224]     Train net output #1: accuracy = 0.596372
I0814 13:04:11.255612 26665 solver.cpp:224]     Train net output #2: accuracy = 0.388215
I0814 13:04:11.255626 26665 solver.cpp:447] Iteration 4310, lr = 1e-05
I0814 13:05:18.661834 26665 solver.cpp:209] Iteration 4320, loss = 0.349431
I0814 13:05:18.661941 26665 solver.cpp:224]     Train net output #0: accuracy = 0.87743
I0814 13:05:18.661965 26665 solver.cpp:224]     Train net output #1: accuracy = 0.685563
I0814 13:05:18.661975 26665 solver.cpp:224]     Train net output #2: accuracy = 0.602723
I0814 13:05:18.661986 26665 solver.cpp:447] Iteration 4320, lr = 1e-05
I0814 13:06:26.108870 26665 solver.cpp:209] Iteration 4330, loss = 0.305344
I0814 13:06:26.108978 26665 solver.cpp:224]     Train net output #0: accuracy = 0.884635
I0814 13:06:26.109004 26665 solver.cpp:224]     Train net output #1: accuracy = 0.741304
I0814 13:06:26.109025 26665 solver.cpp:224]     Train net output #2: accuracy = 0.430423
I0814 13:06:26.109040 26665 solver.cpp:447] Iteration 4330, lr = 1e-05
I0814 13:07:33.532558 26665 solver.cpp:209] Iteration 4340, loss = 0.325505
I0814 13:07:33.532704 26665 solver.cpp:224]     Train net output #0: accuracy = 0.892849
I0814 13:07:33.532729 26665 solver.cpp:224]     Train net output #1: accuracy = 0.634794
I0814 13:07:33.532752 26665 solver.cpp:224]     Train net output #2: accuracy = 0.429422
I0814 13:07:33.532766 26665 solver.cpp:447] Iteration 4340, lr = 1e-05
I0814 13:08:40.940783 26665 solver.cpp:209] Iteration 4350, loss = 0.277795
I0814 13:08:40.940891 26665 solver.cpp:224]     Train net output #0: accuracy = 0.893914
I0814 13:08:40.940917 26665 solver.cpp:224]     Train net output #1: accuracy = 0.766792
I0814 13:08:40.940927 26665 solver.cpp:224]     Train net output #2: accuracy = 0.646268
I0814 13:08:40.940937 26665 solver.cpp:447] Iteration 4350, lr = 1e-05
I0814 13:09:48.389091 26665 solver.cpp:209] Iteration 4360, loss = 0.358923
I0814 13:09:48.389195 26665 solver.cpp:224]     Train net output #0: accuracy = 0.870145
I0814 13:09:48.389221 26665 solver.cpp:224]     Train net output #1: accuracy = 0.660109
I0814 13:09:48.389231 26665 solver.cpp:224]     Train net output #2: accuracy = 0.579721
I0814 13:09:48.389242 26665 solver.cpp:447] Iteration 4360, lr = 1e-05
I0814 13:10:55.848533 26665 solver.cpp:209] Iteration 4370, loss = 0.168799
I0814 13:10:55.848697 26665 solver.cpp:224]     Train net output #0: accuracy = 0.936845
I0814 13:10:55.848722 26665 solver.cpp:224]     Train net output #1: accuracy = 0.710777
I0814 13:10:55.848733 26665 solver.cpp:224]     Train net output #2: accuracy = 0.497257
I0814 13:10:55.848744 26665 solver.cpp:447] Iteration 4370, lr = 1e-05
I0814 13:12:03.274178 26665 solver.cpp:209] Iteration 4380, loss = 0.306279
I0814 13:12:03.274283 26665 solver.cpp:224]     Train net output #0: accuracy = 0.892363
I0814 13:12:03.274308 26665 solver.cpp:224]     Train net output #1: accuracy = 0.676945
I0814 13:12:03.274333 26665 solver.cpp:224]     Train net output #2: accuracy = 0.597744
I0814 13:12:03.274348 26665 solver.cpp:447] Iteration 4380, lr = 1e-05
I0814 13:13:10.696847 26665 solver.cpp:209] Iteration 4390, loss = 0.352704
I0814 13:13:10.696954 26665 solver.cpp:224]     Train net output #0: accuracy = 0.88926
I0814 13:13:10.696979 26665 solver.cpp:224]     Train net output #1: accuracy = 0.716859
I0814 13:13:10.696988 26665 solver.cpp:224]     Train net output #2: accuracy = 0.583888
I0814 13:13:10.697017 26665 solver.cpp:447] Iteration 4390, lr = 1e-05
I0814 13:14:18.119592 26665 solver.cpp:209] Iteration 4400, loss = 0.243717
I0814 13:14:18.119695 26665 solver.cpp:224]     Train net output #0: accuracy = 0.912771
I0814 13:14:18.119720 26665 solver.cpp:224]     Train net output #1: accuracy = 0.61469
I0814 13:14:18.119730 26665 solver.cpp:224]     Train net output #2: accuracy = 0.603915
I0814 13:14:18.119741 26665 solver.cpp:447] Iteration 4400, lr = 1e-05
I0814 13:15:25.547176 26665 solver.cpp:209] Iteration 4410, loss = 0.368104
I0814 13:15:25.547328 26665 solver.cpp:224]     Train net output #0: accuracy = 0.876882
I0814 13:15:25.547354 26665 solver.cpp:224]     Train net output #1: accuracy = 0.684518
I0814 13:15:25.547384 26665 solver.cpp:224]     Train net output #2: accuracy = 0.567032
I0814 13:15:25.547395 26665 solver.cpp:447] Iteration 4410, lr = 1e-05
I0814 13:16:32.974535 26665 solver.cpp:209] Iteration 4420, loss = 0.236481
I0814 13:16:32.974637 26665 solver.cpp:224]     Train net output #0: accuracy = 0.919769
I0814 13:16:32.974663 26665 solver.cpp:224]     Train net output #1: accuracy = 0.814073
I0814 13:16:32.974673 26665 solver.cpp:224]     Train net output #2: accuracy = 0.618732
I0814 13:16:32.974684 26665 solver.cpp:447] Iteration 4420, lr = 1e-05
I0814 13:17:40.398550 26665 solver.cpp:209] Iteration 4430, loss = 0.335235
I0814 13:17:40.398685 26665 solver.cpp:224]     Train net output #0: accuracy = 0.880072
I0814 13:17:40.398711 26665 solver.cpp:224]     Train net output #1: accuracy = 0.68071
I0814 13:17:40.398721 26665 solver.cpp:224]     Train net output #2: accuracy = 0.566553
I0814 13:17:40.398732 26665 solver.cpp:447] Iteration 4430, lr = 1e-05
I0814 13:18:47.825786 26665 solver.cpp:209] Iteration 4440, loss = 0.359374
I0814 13:18:47.825893 26665 solver.cpp:224]     Train net output #0: accuracy = 0.865274
I0814 13:18:47.825918 26665 solver.cpp:224]     Train net output #1: accuracy = 0.73273
I0814 13:18:47.825942 26665 solver.cpp:224]     Train net output #2: accuracy = 0.600809
I0814 13:18:47.825956 26665 solver.cpp:447] Iteration 4440, lr = 1e-05
I0814 13:19:55.254813 26665 solver.cpp:209] Iteration 4450, loss = 0.3525
I0814 13:19:55.254917 26665 solver.cpp:224]     Train net output #0: accuracy = 0.881137
I0814 13:19:55.254942 26665 solver.cpp:224]     Train net output #1: accuracy = 0.65291
I0814 13:19:55.254969 26665 solver.cpp:224]     Train net output #2: accuracy = 0.656106
I0814 13:19:55.254981 26665 solver.cpp:447] Iteration 4450, lr = 1e-05
I0814 13:21:02.727849 26665 solver.cpp:209] Iteration 4460, loss = 0.244091
I0814 13:21:02.728008 26665 solver.cpp:224]     Train net output #0: accuracy = 0.911524
I0814 13:21:02.728032 26665 solver.cpp:224]     Train net output #1: accuracy = 0.632235
I0814 13:21:02.728046 26665 solver.cpp:224]     Train net output #2: accuracy = 0.456161
I0814 13:21:02.728057 26665 solver.cpp:447] Iteration 4460, lr = 1e-05
I0814 13:22:10.159572 26665 solver.cpp:209] Iteration 4470, loss = 0.280873
I0814 13:22:10.159677 26665 solver.cpp:224]     Train net output #0: accuracy = 0.912775
I0814 13:22:10.159703 26665 solver.cpp:224]     Train net output #1: accuracy = 0.654784
I0814 13:22:10.159713 26665 solver.cpp:224]     Train net output #2: accuracy = 0.517915
I0814 13:22:10.159723 26665 solver.cpp:447] Iteration 4470, lr = 1e-05
I0814 13:23:17.580624 26665 solver.cpp:209] Iteration 4480, loss = 0.280302
I0814 13:23:17.580726 26665 solver.cpp:224]     Train net output #0: accuracy = 0.909577
I0814 13:23:17.580752 26665 solver.cpp:224]     Train net output #1: accuracy = 0.803579
I0814 13:23:17.580762 26665 solver.cpp:224]     Train net output #2: accuracy = 0.528456
I0814 13:23:17.580773 26665 solver.cpp:447] Iteration 4480, lr = 1e-05
I0814 13:24:25.002231 26665 solver.cpp:209] Iteration 4490, loss = 0.489467
I0814 13:24:25.002393 26665 solver.cpp:224]     Train net output #0: accuracy = 0.835779
I0814 13:24:25.002418 26665 solver.cpp:224]     Train net output #1: accuracy = 0.676672
I0814 13:24:25.002427 26665 solver.cpp:224]     Train net output #2: accuracy = 0.417366
I0814 13:24:25.002460 26665 solver.cpp:447] Iteration 4490, lr = 1e-05
I0814 13:25:32.435876 26665 solver.cpp:209] Iteration 4500, loss = 0.423185
I0814 13:25:32.435971 26665 solver.cpp:224]     Train net output #0: accuracy = 0.834898
I0814 13:25:32.435986 26665 solver.cpp:224]     Train net output #1: accuracy = 0.575458
I0814 13:25:32.436007 26665 solver.cpp:224]     Train net output #2: accuracy = 0.509773
I0814 13:25:32.436030 26665 solver.cpp:447] Iteration 4500, lr = 1e-05
I0814 13:26:39.853998 26665 solver.cpp:209] Iteration 4510, loss = 0.282318
I0814 13:26:39.854096 26665 solver.cpp:224]     Train net output #0: accuracy = 0.906119
I0814 13:26:39.854121 26665 solver.cpp:224]     Train net output #1: accuracy = 0.719596
I0814 13:26:39.854130 26665 solver.cpp:224]     Train net output #2: accuracy = 0.564999
I0814 13:26:39.854141 26665 solver.cpp:447] Iteration 4510, lr = 1e-05
I0814 13:27:47.284549 26665 solver.cpp:209] Iteration 4520, loss = 0.387493
I0814 13:27:47.284710 26665 solver.cpp:224]     Train net output #0: accuracy = 0.862013
I0814 13:27:47.284735 26665 solver.cpp:224]     Train net output #1: accuracy = 0.637644
I0814 13:27:47.284745 26665 solver.cpp:224]     Train net output #2: accuracy = 0.475243
I0814 13:27:47.284757 26665 solver.cpp:447] Iteration 4520, lr = 1e-05
I0814 13:28:54.726470 26665 solver.cpp:209] Iteration 4530, loss = 0.248168
I0814 13:28:54.726591 26665 solver.cpp:224]     Train net output #0: accuracy = 0.907298
I0814 13:28:54.726618 26665 solver.cpp:224]     Train net output #1: accuracy = 0.736513
I0814 13:28:54.726626 26665 solver.cpp:224]     Train net output #2: accuracy = 0.557276
I0814 13:28:54.726637 26665 solver.cpp:447] Iteration 4530, lr = 1e-05
I0814 13:30:02.143904 26665 solver.cpp:209] Iteration 4540, loss = 0.508183
I0814 13:30:02.144069 26665 solver.cpp:224]     Train net output #0: accuracy = 0.830503
I0814 13:30:02.144095 26665 solver.cpp:224]     Train net output #1: accuracy = 0.711798
I0814 13:30:02.144119 26665 solver.cpp:224]     Train net output #2: accuracy = 0.467666
I0814 13:30:02.144132 26665 solver.cpp:447] Iteration 4540, lr = 1e-05
I0814 13:31:09.565935 26665 solver.cpp:209] Iteration 4550, loss = 0.27271
I0814 13:31:09.566038 26665 solver.cpp:224]     Train net output #0: accuracy = 0.90171
I0814 13:31:09.566063 26665 solver.cpp:224]     Train net output #1: accuracy = 0.68716
I0814 13:31:09.566073 26665 solver.cpp:224]     Train net output #2: accuracy = 0.456043
I0814 13:31:09.566099 26665 solver.cpp:447] Iteration 4550, lr = 1e-05
I0814 13:32:16.977363 26665 solver.cpp:209] Iteration 4560, loss = 0.455638
I0814 13:32:16.977460 26665 solver.cpp:224]     Train net output #0: accuracy = 0.835747
I0814 13:32:16.977486 26665 solver.cpp:224]     Train net output #1: accuracy = 0.59719
I0814 13:32:16.977496 26665 solver.cpp:224]     Train net output #2: accuracy = 0.397064
I0814 13:32:16.977507 26665 solver.cpp:447] Iteration 4560, lr = 1e-05
I0814 13:33:24.405736 26665 solver.cpp:209] Iteration 4570, loss = 0.258291
I0814 13:33:24.405836 26665 solver.cpp:224]     Train net output #0: accuracy = 0.904336
I0814 13:33:24.405861 26665 solver.cpp:224]     Train net output #1: accuracy = 0.72255
I0814 13:33:24.405871 26665 solver.cpp:224]     Train net output #2: accuracy = 0.655695
I0814 13:33:24.405882 26665 solver.cpp:447] Iteration 4570, lr = 1e-05
I0814 13:34:31.803457 26665 solver.cpp:209] Iteration 4580, loss = 0.283069
I0814 13:34:31.803561 26665 solver.cpp:224]     Train net output #0: accuracy = 0.911435
I0814 13:34:31.803586 26665 solver.cpp:224]     Train net output #1: accuracy = 0.646124
I0814 13:34:31.803596 26665 solver.cpp:224]     Train net output #2: accuracy = 0.424866
I0814 13:34:31.803607 26665 solver.cpp:447] Iteration 4580, lr = 1e-05
I0814 13:35:39.226768 26665 solver.cpp:209] Iteration 4590, loss = 0.322419
I0814 13:35:39.226872 26665 solver.cpp:224]     Train net output #0: accuracy = 0.890566
I0814 13:35:39.226897 26665 solver.cpp:224]     Train net output #1: accuracy = 0.663251
I0814 13:35:39.226907 26665 solver.cpp:224]     Train net output #2: accuracy = 0.488438
I0814 13:35:39.226917 26665 solver.cpp:447] Iteration 4590, lr = 1e-05
I0814 13:36:46.636818 26665 solver.cpp:209] Iteration 4600, loss = 0.348004
I0814 13:36:46.636927 26665 solver.cpp:224]     Train net output #0: accuracy = 0.884104
I0814 13:36:46.636952 26665 solver.cpp:224]     Train net output #1: accuracy = 0.635348
I0814 13:36:46.636975 26665 solver.cpp:224]     Train net output #2: accuracy = 0.459546
I0814 13:36:46.636988 26665 solver.cpp:447] Iteration 4600, lr = 1e-05
I0814 13:37:54.069710 26665 solver.cpp:209] Iteration 4610, loss = 0.363217
I0814 13:37:54.069877 26665 solver.cpp:224]     Train net output #0: accuracy = 0.874682
I0814 13:37:54.069903 26665 solver.cpp:224]     Train net output #1: accuracy = 0.739245
I0814 13:37:54.069926 26665 solver.cpp:224]     Train net output #2: accuracy = 0.49941
I0814 13:37:54.069938 26665 solver.cpp:447] Iteration 4610, lr = 1e-05
I0814 13:39:01.469923 26665 solver.cpp:209] Iteration 4620, loss = 0.380353
